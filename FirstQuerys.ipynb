{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bece517",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.13.2' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Let's import the libraries we will need\n",
    "import pyspark\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e32ab475",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/12 21:49:29 WARN Utils: Your hostname, Alejandro resolves to a loopback address: 127.0.1.1; using 192.168.1.109 instead (on interface enp46s0)\n",
      "25/05/12 21:49:29 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/05/12 21:49:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.109:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=pyspark-shell>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/12 21:49:43 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"SPARK_HOME\"] = \"/home/alejandro/Escritorio/venv/lib/python3.12/site-packages/pyspark\"\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"python3\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"python3\"\n",
    "\n",
    "\n",
    "\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext.getOrCreate()\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aefadfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f90ba06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.109:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7140cd95dd60>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "123eeb9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Muestra de los datos originales:\n",
      "+--------+--------------------+---------------------+---------------+-------------+------------------+------------------+----------+------------------+------------------+-----------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|  pickup_longitude|   pickup_latitude|RatecodeID|store_and_fwd_flag| dropoff_longitude| dropoff_latitude|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|\n",
      "+--------+--------------------+---------------------+---------------+-------------+------------------+------------------+----------+------------------+------------------+-----------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+\n",
      "|       1| 2016-03-01 00:00:00|  2016-03-01 00:07:55|              1|          2.5|-73.97674560546875| 40.76515197753906|         1|                 N|-74.00426483154297|40.74612808227539|           1|        9.0|  0.5|    0.5|      2.05|         0.0|                  0.3|       12.35|\n",
      "|       1| 2016-03-01 00:00:00|  2016-03-01 00:11:06|              1|          2.9|-73.98348236083984| 40.76792526245117|         1|                 N|-74.00594329833984| 40.7331657409668|           1|       11.0|  0.5|    0.5|      3.05|         0.0|                  0.3|       15.35|\n",
      "|       2| 2016-03-01 00:00:00|  2016-03-01 00:31:06|              2|        19.98|-73.78202056884766| 40.64480972290039|         1|                 N|-73.97454071044922| 40.6757698059082|           1|       54.5|  0.5|    0.5|       8.0|         0.0|                  0.3|        63.8|\n",
      "|       2| 2016-03-01 00:00:00|  2016-03-01 00:00:00|              3|        10.78|-73.86341857910156|40.769813537597656|         1|                 N|-73.96965026855469|40.75776672363281|           1|       31.5|  0.0|    0.5|      3.78|        5.54|                  0.3|       41.62|\n",
      "|       2| 2016-03-01 00:00:00|  2016-03-01 00:00:00|              5|        30.43|-73.97174072265625| 40.79218292236328|         3|                 N|-74.17716979980469|40.69505310058594|           1|       98.0|  0.0|    0.0|       0.0|        15.5|                  0.3|       113.8|\n",
      "+--------+--------------------+---------------------+---------------+-------------+------------------+------------------+----------+------------------+------------------+-----------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "Esquema del dataframe modificado:\n",
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- pickup_longitude: double (nullable = true)\n",
      " |-- pickup_latitude: double (nullable = true)\n",
      " |-- RatecodeID: integer (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- dropoff_longitude: double (nullable = true)\n",
      " |-- dropoff_latitude: double (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- pickup_quadrant: string (nullable = false)\n",
      " |-- dropoff_quadrant: string (nullable = false)\n",
      " |-- day_of_week: string (nullable = true)\n",
      "\n",
      "\n",
      "QUERY 1: Cuadrantes de origen y destino más comunes\n",
      "\n",
      "Cuadrantes de origen más comunes:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------+\n",
      "|pickup_quadrant|  count|\n",
      "+---------------+-------+\n",
      "|             NE|4606849|\n",
      "|             SW|4264446|\n",
      "|             NW|2292330|\n",
      "|             SE| 865326|\n",
      "|        Invalid| 182001|\n",
      "+---------------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados guardados en el directorio 'resultados/cuadrantes_origen'\n",
      "\n",
      "Cuadrantes de destino más comunes:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------+\n",
      "|dropoff_quadrant|  count|\n",
      "+----------------+-------+\n",
      "|              NE|4805320|\n",
      "|              SW|3902685|\n",
      "|              NW|2102949|\n",
      "|              SE|1228838|\n",
      "|         Invalid| 171160|\n",
      "+----------------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados guardados en el directorio 'resultados/cuadrantes_destino'\n",
      "\n",
      "Rutas más comunes (origen-destino):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------------+-------+\n",
      "|pickup_quadrant|dropoff_quadrant|  count|\n",
      "+---------------+----------------+-------+\n",
      "|             NE|              NE|2785957|\n",
      "|             SW|              SW|2262292|\n",
      "|             NW|              NE| 893975|\n",
      "|             SW|              NE| 873371|\n",
      "|             NE|              SW| 774190|\n",
      "|             NE|              NW| 729566|\n",
      "|             NW|              NW| 666227|\n",
      "|             SW|              NW| 607599|\n",
      "|             NW|              SW| 583532|\n",
      "|             SW|              SE| 515465|\n",
      "+---------------+----------------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados guardados en el directorio 'resultados/rutas_comunes'\n",
      "\n",
      "QUERY 2: Número de viajes e ingreso promedio por día de la semana\n",
      "\n",
      "Número de viajes e ingreso promedio por día de la semana:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+------------------+\n",
      "|day_of_week|trip_count|        avg_income|\n",
      "+-----------+----------+------------------+\n",
      "|     Monday|   1421600|16.102126793719737|\n",
      "|    Tuesday|   1874217|15.984783837696066|\n",
      "|  Wednesday|   1957116|16.213695028783167|\n",
      "|   Thursday|   2035529|16.742025601170454|\n",
      "|     Friday|   1695920|16.134756839903744|\n",
      "|   Saturday|   1739430|  14.9198607359547|\n",
      "|     Sunday|   1487140|  16.1106056053556|\n",
      "+-----------+----------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados guardados en el directorio 'resultados/viajes_por_dia'\n",
      "\n",
      "Promedio de propinas por día de la semana:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+-------------------+\n",
      "|day_of_week|           avg_tip|     tip_percentage|\n",
      "+-----------+------------------+-------------------+\n",
      "|     Monday|1.8086669105233553| 0.1594104078518886|\n",
      "|    Tuesday|1.8355890113044677|0.17392294968488886|\n",
      "|  Wednesday|1.8730552455756972|0.20401391893740248|\n",
      "|   Thursday|1.9009165578087268| 0.1842776304151854|\n",
      "|     Friday|1.7997616750789425|  0.148607523776172|\n",
      "|   Saturday|1.5735263735821807|0.17578792655552652|\n",
      "|     Sunday|1.7168454415858982|0.16448129032788741|\n",
      "+-----------+------------------+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados guardados en el directorio 'resultados/propinas_por_dia'\n",
      "\n",
      "Análisis adicional: Tiempo promedio de viaje por cuadrante\n",
      "\n",
      "Tiempo promedio de viaje por cuadrante de origen:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+----------+\n",
      "|pickup_quadrant|avg_duration_minutes|trip_count|\n",
      "+---------------+--------------------+----------+\n",
      "|             SE|  23.314068524463657|    865326|\n",
      "|             SW|  15.351941243950597|   4264446|\n",
      "|             NW|  15.202678981647523|   2292330|\n",
      "|             NE|   15.08916382108472|   4606849|\n",
      "|        Invalid|   7.816470568843067|    182001|\n",
      "+---------------+--------------------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados guardados en el directorio 'resultados/duracion_por_origen'\n",
      "\n",
      "Tiempo promedio de viaje por cuadrante de destino:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------------+----------+\n",
      "|dropoff_quadrant|avg_duration_minutes|trip_count|\n",
      "+----------------+--------------------+----------+\n",
      "|              SE|  21.746755194744974|   1228838|\n",
      "|              SW|   15.31795916144919|   3902685|\n",
      "|              NW|  14.982833872813877|   2102949|\n",
      "|              NE|  14.773323632973527|   4805320|\n",
      "|         Invalid|  14.164315727973854|    171160|\n",
      "+----------------+--------------------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados guardados en el directorio 'resultados/duracion_por_destino'\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, dayofweek, date_format, count, avg, when, lit\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType, TimestampType\n",
    "\n",
    "# Crear directorio de resultados si no existe\n",
    "import os\n",
    "if not os.path.exists(\"resultados\"):\n",
    "    os.makedirs(\"resultados\")\n",
    "    print(\"Directorio 'resultados' creado.\")\n",
    "\n",
    "# Definir el esquema para los datos\n",
    "schema = StructType([\n",
    "    StructField(\"VendorID\", IntegerType(), True),\n",
    "    StructField(\"tpep_pickup_datetime\", TimestampType(), True),\n",
    "    StructField(\"tpep_dropoff_datetime\", TimestampType(), True),\n",
    "    StructField(\"passenger_count\", IntegerType(), True),\n",
    "    StructField(\"trip_distance\", DoubleType(), True),\n",
    "    StructField(\"pickup_longitude\", DoubleType(), True),\n",
    "    StructField(\"pickup_latitude\", DoubleType(), True),\n",
    "    StructField(\"RatecodeID\", IntegerType(), True),\n",
    "    StructField(\"store_and_fwd_flag\", StringType(), True),\n",
    "    StructField(\"dropoff_longitude\", DoubleType(), True),\n",
    "    StructField(\"dropoff_latitude\", DoubleType(), True),\n",
    "    StructField(\"payment_type\", IntegerType(), True),\n",
    "    StructField(\"fare_amount\", DoubleType(), True),\n",
    "    StructField(\"extra\", DoubleType(), True),\n",
    "    StructField(\"mta_tax\", DoubleType(), True),\n",
    "    StructField(\"tip_amount\", DoubleType(), True),\n",
    "    StructField(\"tolls_amount\", DoubleType(), True),\n",
    "    StructField(\"improvement_surcharge\", DoubleType(), True),\n",
    "    StructField(\"total_amount\", DoubleType(), True)\n",
    "])\n",
    "\n",
    "# Cargar los datos CSV\n",
    "# Usamos la ruta relativa según la estructura del proyecto descrita\n",
    "df = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(schema) \\\n",
    "    .load(\"data/yellow_tripdata_2016-03.csv\")\n",
    "\n",
    "# Mostrar las primeras filas para verificar que los datos se cargaron correctamente\n",
    "print(\"Muestra de los datos originales:\")\n",
    "df.show(5)\n",
    "\n",
    "# Función auxiliar para determinar el cuadrante basado en coordenadas\n",
    "def add_quadrants(df):\n",
    "    # Para Nueva York, aproximadamente:\n",
    "    # Centro de Manhattan está alrededor de -73.98, 40.75\n",
    "    # Dividimos en cuadrantes basados en estas coordenadas centrales\n",
    "    return df.withColumn(\n",
    "        \"pickup_quadrant\", \n",
    "        when((col(\"pickup_longitude\") == 0) | (col(\"pickup_latitude\") == 0), \"Invalid\")\n",
    "        .when((col(\"pickup_longitude\") > -73.98) & (col(\"pickup_latitude\") > 40.75), \"NE\")\n",
    "        .when((col(\"pickup_longitude\") > -73.98) & (col(\"pickup_latitude\") <= 40.75), \"SE\")\n",
    "        .when((col(\"pickup_longitude\") <= -73.98) & (col(\"pickup_latitude\") > 40.75), \"NW\")\n",
    "        .when((col(\"pickup_longitude\") <= -73.98) & (col(\"pickup_latitude\") <= 40.75), \"SW\")\n",
    "        .otherwise(\"Unknown\")\n",
    "    ).withColumn(\n",
    "        \"dropoff_quadrant\", \n",
    "        when((col(\"dropoff_longitude\") == 0) | (col(\"dropoff_latitude\") == 0), \"Invalid\")\n",
    "        .when((col(\"dropoff_longitude\") > -73.98) & (col(\"dropoff_latitude\") > 40.75), \"NE\")\n",
    "        .when((col(\"dropoff_longitude\") > -73.98) & (col(\"dropoff_latitude\") <= 40.75), \"SE\")\n",
    "        .when((col(\"dropoff_longitude\") <= -73.98) & (col(\"dropoff_latitude\") > 40.75), \"NW\")\n",
    "        .when((col(\"dropoff_longitude\") <= -73.98) & (col(\"dropoff_latitude\") <= 40.75), \"SW\")\n",
    "        .otherwise(\"Unknown\")\n",
    "    )\n",
    "\n",
    "# Añadir columnas de cuadrantes\n",
    "df_with_quadrants = add_quadrants(df)\n",
    "\n",
    "# Añadir columna del día de la semana\n",
    "df_with_days = df_with_quadrants.withColumn(\n",
    "    \"day_of_week\", \n",
    "    date_format(col(\"tpep_pickup_datetime\"), \"EEEE\")\n",
    ")\n",
    "\n",
    "# Mostrar el esquema del dataframe modificado\n",
    "print(\"\\nEsquema del dataframe modificado:\")\n",
    "df_with_days.printSchema()\n",
    "\n",
    "# Guardar el dataframe modificado para su uso posterior si es necesario\n",
    "# df_with_days.write.mode(\"overwrite\").parquet(\"path_to_save_modified_data\")\n",
    "\n",
    "# QUERY 1: Cuadrantes de origen y destino más comunes\n",
    "print(\"\\nQUERY 1: Cuadrantes de origen y destino más comunes\")\n",
    "\n",
    "# Los cuadrantes de origen más comunes\n",
    "pickup_quadrants = df_with_days.groupBy(\"pickup_quadrant\") \\\n",
    "    .count() \\\n",
    "    .orderBy(col(\"count\").desc())\n",
    "\n",
    "print(\"\\nCuadrantes de origen más comunes:\")\n",
    "pickup_quadrants.show()\n",
    "\n",
    "# Guardar resultados de cuadrantes de origen\n",
    "pickup_quadrants.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"resultados/cuadrantes_origen\")\n",
    "print(\"Resultados guardados en el directorio 'resultados/cuadrantes_origen'\")\n",
    "\n",
    "# Los cuadrantes de destino más comunes\n",
    "dropoff_quadrants = df_with_days.groupBy(\"dropoff_quadrant\") \\\n",
    "    .count() \\\n",
    "    .orderBy(col(\"count\").desc())\n",
    "\n",
    "print(\"\\nCuadrantes de destino más comunes:\")\n",
    "dropoff_quadrants.show()\n",
    "\n",
    "# Guardar resultados de cuadrantes de destino\n",
    "dropoff_quadrants.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"resultados/cuadrantes_destino\")\n",
    "print(\"Resultados guardados en el directorio 'resultados/cuadrantes_destino'\")\n",
    "\n",
    "# Las rutas más comunes (combinación de origen-destino)\n",
    "routes = df_with_days.groupBy(\"pickup_quadrant\", \"dropoff_quadrant\") \\\n",
    "    .count() \\\n",
    "    .orderBy(col(\"count\").desc())\n",
    "\n",
    "print(\"\\nRutas más comunes (origen-destino):\")\n",
    "routes.show(10)\n",
    "\n",
    "# Guardar resultados de rutas más comunes\n",
    "routes.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"resultados/rutas_comunes\")\n",
    "print(\"Resultados guardados en el directorio 'resultados/rutas_comunes'\")\n",
    "\n",
    "# QUERY 2: Número de viajes e ingreso promedio por día de la semana\n",
    "print(\"\\nQUERY 2: Número de viajes e ingreso promedio por día de la semana\")\n",
    "\n",
    "trips_by_day = df_with_days.groupBy(\"day_of_week\") \\\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"trip_count\"),\n",
    "        avg(\"total_amount\").alias(\"avg_income\")\n",
    "    ) \\\n",
    "    .orderBy(\n",
    "        # Ordenar por día de la semana (lunes a domingo)\n",
    "        when(col(\"day_of_week\") == \"Monday\", 1)\n",
    "        .when(col(\"day_of_week\") == \"Tuesday\", 2)\n",
    "        .when(col(\"day_of_week\") == \"Wednesday\", 3)\n",
    "        .when(col(\"day_of_week\") == \"Thursday\", 4)\n",
    "        .when(col(\"day_of_week\") == \"Friday\", 5)\n",
    "        .when(col(\"day_of_week\") == \"Saturday\", 6)\n",
    "        .when(col(\"day_of_week\") == \"Sunday\", 7)\n",
    "    )\n",
    "\n",
    "print(\"\\nNúmero de viajes e ingreso promedio por día de la semana:\")\n",
    "trips_by_day.show()\n",
    "\n",
    "# Guardar los resultados como CSV para análisis posterior\n",
    "trips_by_day.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"resultados/viajes_por_dia\")\n",
    "print(\"Resultados guardados en el directorio 'resultados/viajes_por_dia'\")\n",
    "\n",
    "# Análisis adicional: Promedio de propinas por día de la semana\n",
    "tips_by_day = df_with_days.groupBy(\"day_of_week\") \\\n",
    "    .agg(\n",
    "        avg(\"tip_amount\").alias(\"avg_tip\"),\n",
    "        avg(col(\"tip_amount\") / col(\"fare_amount\")).alias(\"tip_percentage\")\n",
    "    ) \\\n",
    "    .orderBy(\n",
    "        when(col(\"day_of_week\") == \"Monday\", 1)\n",
    "        .when(col(\"day_of_week\") == \"Tuesday\", 2)\n",
    "        .when(col(\"day_of_week\") == \"Wednesday\", 3)\n",
    "        .when(col(\"day_of_week\") == \"Thursday\", 4)\n",
    "        .when(col(\"day_of_week\") == \"Friday\", 5)\n",
    "        .when(col(\"day_of_week\") == \"Saturday\", 6)\n",
    "        .when(col(\"day_of_week\") == \"Sunday\", 7)\n",
    "    )\n",
    "\n",
    "print(\"\\nPromedio de propinas por día de la semana:\")\n",
    "tips_by_day.show()\n",
    "\n",
    "# Guardar los resultados de propinas como CSV\n",
    "tips_by_day.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"resultados/propinas_por_dia\")\n",
    "print(\"Resultados guardados en el directorio 'resultados/propinas_por_dia'\")\n",
    "\n",
    "# Análisis adicional: Tiempo promedio de viaje por cuadrante\n",
    "from pyspark.sql.functions import unix_timestamp, round as spark_round\n",
    "\n",
    "print(\"\\nAnálisis adicional: Tiempo promedio de viaje por cuadrante\")\n",
    "df_with_duration = df_with_days.withColumn(\n",
    "    \"trip_duration_minutes\", \n",
    "    spark_round((unix_timestamp(col(\"tpep_dropoff_datetime\")) - unix_timestamp(col(\"tpep_pickup_datetime\"))) / 60, 2)\n",
    ")\n",
    "\n",
    "# Tiempo promedio de viaje por cuadrante de origen\n",
    "avg_duration_by_pickup = df_with_duration.groupBy(\"pickup_quadrant\") \\\n",
    "    .agg(\n",
    "        avg(\"trip_duration_minutes\").alias(\"avg_duration_minutes\"),\n",
    "        count(\"*\").alias(\"trip_count\")\n",
    "    ) \\\n",
    "    .orderBy(col(\"avg_duration_minutes\").desc())\n",
    "\n",
    "print(\"\\nTiempo promedio de viaje por cuadrante de origen:\")\n",
    "avg_duration_by_pickup.show()\n",
    "\n",
    "# Guardar resultados\n",
    "avg_duration_by_pickup.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"resultados/duracion_por_origen\")\n",
    "print(\"Resultados guardados en el directorio 'resultados/duracion_por_origen'\")\n",
    "\n",
    "# Tiempo promedio de viaje por cuadrante de destino\n",
    "avg_duration_by_dropoff = df_with_duration.groupBy(\"dropoff_quadrant\") \\\n",
    "    .agg(\n",
    "        avg(\"trip_duration_minutes\").alias(\"avg_duration_minutes\"),\n",
    "        count(\"*\").alias(\"trip_count\")\n",
    "    ) \\\n",
    "    .orderBy(col(\"avg_duration_minutes\").desc())\n",
    "\n",
    "print(\"\\nTiempo promedio de viaje por cuadrante de destino:\")\n",
    "avg_duration_by_dropoff.show()\n",
    "\n",
    "# Guardar resultados\n",
    "avg_duration_by_dropoff.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"resultados/duracion_por_destino\")\n",
    "print(\"Resultados guardados en el directorio 'resultados/duracion_por_destino'\")\n",
    "\n",
    "# Detener la sesión de Spark\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
