{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43983940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's import the libraries we will need\n",
    "import pyspark\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a608fd49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/22 12:44:28 WARN Utils: Your hostname, Alejandro resolves to a loopback address: 127.0.1.1; using 192.168.1.109 instead (on interface enp46s0)\n",
      "25/05/22 12:44:28 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/05/22 12:44:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.109:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>DataProcessing</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7a64801fe0f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"SPARK_HOME\"] = \"/home/alejandro/Escritorio/venv/lib/python3.12/site-packages/pyspark\"\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"python3\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"python3\"\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "\n",
    "# Detener contextos previos si existen\n",
    "try:\n",
    "   sc.stop()\n",
    "except:\n",
    "   pass\n",
    "\n",
    "# Crear SparkSession con configuración de memoria\n",
    "spark = SparkSession.builder \\\n",
    "   .appName(\"DataProcessing\") \\\n",
    "   .config(\"spark.driver.memory\", \"4g\") \\\n",
    "   .config(\"spark.executor.memory\", \"4g\") \\\n",
    "   .config(\"spark.driver.maxResultSize\", \"2g\") \\\n",
    "   .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "   .getOrCreate()\n",
    "\n",
    "# Obtener SparkContext desde la sesión\n",
    "sc = spark.sparkContext\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cc036ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Library Imports and Setup\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder\n",
    "from pyspark.ml.regression import RandomForestRegressor, GBTRegressor, LinearRegression\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier\n",
    "from pyspark.ml.evaluation import RegressionEvaluator, MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.stat import Correlation\n",
    "import random\n",
    "import math\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "565aff7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Haversine Distance UDF\n",
    "@udf(returnType=DoubleType())\n",
    "def calculate_haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    if any(coord is None for coord in [lat1, lon1, lat2, lon2]):\n",
    "        return None\n",
    "    \n",
    "    lat1_rad, lon1_rad = math.radians(lat1), math.radians(lon1)\n",
    "    lat2_rad, lon2_rad = math.radians(lat2), math.radians(lon2)\n",
    "    \n",
    "    dlat = lat2_rad - lat1_rad\n",
    "    dlon = lon2_rad - lon1_rad\n",
    "    a = math.sin(dlat/2)**2 + math.cos(lat1_rad) * math.cos(lat2_rad) * math.sin(dlon/2)**2\n",
    "    c = 2 * math.asin(math.sqrt(a))\n",
    "    \n",
    "    r = 3959\n",
    "    return c * r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b390ab49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV data loaded successfully from: data/yellow_tripdata_2016-03.csv\n",
      "Sample of original data:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+------------------+------------------+----------+------------------+------------------+-----------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|  pickup_longitude|   pickup_latitude|RatecodeID|store_and_fwd_flag| dropoff_longitude| dropoff_latitude|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|\n",
      "+--------+--------------------+---------------------+---------------+-------------+------------------+------------------+----------+------------------+------------------+-----------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+\n",
      "|       1| 2016-03-01 00:00:00|  2016-03-01 00:07:55|              1|          2.5|-73.97674560546875| 40.76515197753906|         1|                 N|-74.00426483154297|40.74612808227539|           1|        9.0|  0.5|    0.5|      2.05|         0.0|                  0.3|       12.35|\n",
      "|       1| 2016-03-01 00:00:00|  2016-03-01 00:11:06|              1|          2.9|-73.98348236083984| 40.76792526245117|         1|                 N|-74.00594329833984| 40.7331657409668|           1|       11.0|  0.5|    0.5|      3.05|         0.0|                  0.3|       15.35|\n",
      "|       2| 2016-03-01 00:00:00|  2016-03-01 00:31:06|              2|        19.98|-73.78202056884766| 40.64480972290039|         1|                 N|-73.97454071044922| 40.6757698059082|           1|       54.5|  0.5|    0.5|       8.0|         0.0|                  0.3|        63.8|\n",
      "|       2| 2016-03-01 00:00:00|  2016-03-01 00:00:00|              3|        10.78|-73.86341857910156|40.769813537597656|         1|                 N|-73.96965026855469|40.75776672363281|           1|       31.5|  0.0|    0.5|      3.78|        5.54|                  0.3|       41.62|\n",
      "|       2| 2016-03-01 00:00:00|  2016-03-01 00:00:00|              5|        30.43|-73.97174072265625| 40.79218292236328|         3|                 N|-74.17716979980469|40.69505310058594|           1|       98.0|  0.0|    0.0|       0.0|        15.5|                  0.3|       113.8|\n",
      "+--------+--------------------+---------------------+---------------+-------------+------------------+------------------+----------+------------------+------------------+-----------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                        (0 + 20) / 20]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: 12210952 records\n",
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: string (nullable = true)\n",
      " |-- tpep_dropoff_datetime: string (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- pickup_longitude: double (nullable = true)\n",
      " |-- pickup_latitude: double (nullable = true)\n",
      " |-- RatecodeID: integer (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- dropoff_longitude: double (nullable = true)\n",
      " |-- dropoff_latitude: double (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Data Loading (CSV or Sample Data Generation)\n",
    "def load_or_create_data(spark, csv_path=None, num_records=5000):\n",
    "    if csv_path:\n",
    "        schema = StructType([\n",
    "            StructField(\"VendorID\", IntegerType(), True),\n",
    "            StructField(\"tpep_pickup_datetime\", StringType(), True),\n",
    "            StructField(\"tpep_dropoff_datetime\", StringType(), True),\n",
    "            StructField(\"passenger_count\", IntegerType(), True),\n",
    "            StructField(\"trip_distance\", DoubleType(), True),\n",
    "            StructField(\"pickup_longitude\", DoubleType(), True),\n",
    "            StructField(\"pickup_latitude\", DoubleType(), True),\n",
    "            StructField(\"RatecodeID\", IntegerType(), True),\n",
    "            StructField(\"store_and_fwd_flag\", StringType(), True),\n",
    "            StructField(\"dropoff_longitude\", DoubleType(), True),\n",
    "            StructField(\"dropoff_latitude\", DoubleType(), True),\n",
    "            StructField(\"payment_type\", IntegerType(), True),\n",
    "            StructField(\"fare_amount\", DoubleType(), True),\n",
    "            StructField(\"extra\", DoubleType(), True),\n",
    "            StructField(\"mta_tax\", DoubleType(), True),\n",
    "            StructField(\"tip_amount\", DoubleType(), True),\n",
    "            StructField(\"tolls_amount\", DoubleType(), True),\n",
    "            StructField(\"improvement_surcharge\", DoubleType(), True),\n",
    "            StructField(\"total_amount\", DoubleType(), True)\n",
    "        ])\n",
    "        \n",
    "        try:\n",
    "            df = spark.read.format(\"csv\") \\\n",
    "                .option(\"header\", \"true\") \\\n",
    "                .schema(schema) \\\n",
    "                .load(csv_path)\n",
    "            \n",
    "            print(f\"CSV data loaded successfully from: {csv_path}\")\n",
    "            print(\"Sample of original data:\")\n",
    "            df.show(5)\n",
    "            return df\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading CSV: {e}\")\n",
    "            print(\"Falling back to sample data generation...\")\n",
    "    \n",
    "    print(\"Generating sample data...\")\n",
    "    sample_schema = StructType([\n",
    "        StructField(\"VendorID\", IntegerType(), True),\n",
    "        StructField(\"tpep_pickup_datetime\", StringType(), False),\n",
    "        StructField(\"tpep_dropoff_datetime\", StringType(), False),\n",
    "        StructField(\"passenger_count\", IntegerType(), False),\n",
    "        StructField(\"trip_distance\", DoubleType(), False),\n",
    "        StructField(\"pickup_longitude\", DoubleType(), False),\n",
    "        StructField(\"pickup_latitude\", DoubleType(), False),\n",
    "        StructField(\"RatecodeID\", IntegerType(), True),\n",
    "        StructField(\"store_and_fwd_flag\", StringType(), True),\n",
    "        StructField(\"dropoff_longitude\", DoubleType(), False),\n",
    "        StructField(\"dropoff_latitude\", DoubleType(), False),\n",
    "        StructField(\"payment_type\", IntegerType(), True),\n",
    "        StructField(\"fare_amount\", DoubleType(), False),\n",
    "        StructField(\"extra\", DoubleType(), True),\n",
    "        StructField(\"mta_tax\", DoubleType(), True),\n",
    "        StructField(\"tip_amount\", DoubleType(), True),\n",
    "        StructField(\"tolls_amount\", DoubleType(), True),\n",
    "        StructField(\"improvement_surcharge\", DoubleType(), True),\n",
    "        StructField(\"total_amount\", DoubleType(), False)\n",
    "    ])\n",
    "    \n",
    "    sample_data = []\n",
    "    base_date = datetime(2016, 3, 1)\n",
    "    \n",
    "    nyc_bounds = {\n",
    "        'lat_min': 40.4774, 'lat_max': 40.9176,\n",
    "        'lon_min': -74.2591, 'lon_max': -73.7004\n",
    "    }\n",
    "    \n",
    "    for i in range(num_records):\n",
    "        pickup_time = base_date + timedelta(\n",
    "            days=random.randint(0, 30),\n",
    "            hours=random.randint(0, 23),\n",
    "            minutes=random.randint(0, 59),\n",
    "            seconds=random.randint(0, 59)\n",
    "        )\n",
    "        \n",
    "        passenger_count = random.choices([1, 2, 3, 4, 5, 6], weights=[40, 25, 15, 10, 7, 3])[0]\n",
    "        trip_distance = random.uniform(0.5, 25.0)\n",
    "        \n",
    "        pickup_lat = random.uniform(nyc_bounds['lat_min'], nyc_bounds['lat_max'])\n",
    "        pickup_lon = random.uniform(nyc_bounds['lon_min'], nyc_bounds['lon_max'])\n",
    "        dropoff_lat = random.uniform(nyc_bounds['lat_min'], nyc_bounds['lat_max'])\n",
    "        dropoff_lon = random.uniform(nyc_bounds['lon_min'], nyc_bounds['lon_max'])\n",
    "        \n",
    "        base_duration = trip_distance * random.uniform(2.5, 6.0)\n",
    "        \n",
    "        hour = pickup_time.hour\n",
    "        if 7 <= hour <= 9 or 17 <= hour <= 19:\n",
    "            base_duration *= random.uniform(1.8, 2.8)\n",
    "        elif 22 <= hour or hour <= 5:\n",
    "            base_duration *= random.uniform(0.8, 1.3)\n",
    "        else:\n",
    "            base_duration *= random.uniform(1.0, 1.5)\n",
    "        \n",
    "        if pickup_time.weekday() in [5, 6]:\n",
    "            base_duration *= random.uniform(0.9, 1.4)\n",
    "        \n",
    "        base_duration = max(1, min(180, base_duration))\n",
    "        \n",
    "        dropoff_time = pickup_time + timedelta(minutes=base_duration)\n",
    "        \n",
    "        base_fare = 2.50\n",
    "        distance_fare = trip_distance * random.uniform(2.50, 3.50)\n",
    "        time_fare = base_duration * random.uniform(0.30, 0.60)\n",
    "        fare_amount = base_fare + distance_fare + time_fare\n",
    "        \n",
    "        tip = fare_amount * random.uniform(0, 0.25)\n",
    "        extras = random.uniform(0, 3.0)\n",
    "        total_amount = fare_amount + tip + extras\n",
    "        \n",
    "        sample_data.append((\n",
    "            random.choice([1, 2]),\n",
    "            pickup_time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            dropoff_time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            passenger_count,\n",
    "            round(trip_distance, 2),\n",
    "            round(pickup_lon, 6),\n",
    "            round(pickup_lat, 6),\n",
    "            random.choice([1, 2, 3, 4, 5]),\n",
    "            random.choice(['N', 'Y']),\n",
    "            round(dropoff_lon, 6),\n",
    "            round(dropoff_lat, 6),\n",
    "            random.choice([1, 2, 3, 4]),\n",
    "            round(fare_amount, 2),\n",
    "            round(random.uniform(0, 1), 2),\n",
    "            0.50,\n",
    "            round(tip, 2),\n",
    "            round(random.uniform(0, 5), 2),\n",
    "            0.30,\n",
    "            round(total_amount, 2)\n",
    "        ))\n",
    "    \n",
    "    df = spark.createDataFrame(sample_data, sample_schema)\n",
    "    return df\n",
    "\n",
    "# Load data - Change csv_path to your actual file path or set to None for sample data\n",
    "csv_path = \"data/yellow_tripdata_2016-03.csv\"  # Set to None to use sample data\n",
    "df_raw = load_or_create_data(spark, csv_path=csv_path, num_records=5000)\n",
    "print(f\"Dataset loaded: {df_raw.count()} records\")\n",
    "df_raw.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35170bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/22 12:44:42 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n",
      "[Stage 7:=======================================>                 (14 + 6) / 20]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records after filtering: 11937106 (removed: 273846)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#  Data Preprocessing\n",
    "def preprocess_data(df):\n",
    "    df = df.withColumn(\"pickup_datetime\", \n",
    "                      to_timestamp(col(\"tpep_pickup_datetime\"), \"yyyy-MM-dd HH:mm:ss\"))\n",
    "    df = df.withColumn(\"dropoff_datetime\", \n",
    "                      to_timestamp(col(\"tpep_dropoff_datetime\"), \"yyyy-MM-dd HH:mm:ss\"))\n",
    "    \n",
    "    df = df.withColumn(\"trip_duration_minutes\", \n",
    "                      (unix_timestamp(\"dropoff_datetime\") - unix_timestamp(\"pickup_datetime\")) / 60.0)\n",
    "    \n",
    "    df = df.withColumn(\"pickup_hour\", hour(\"pickup_datetime\")) \\\n",
    "           .withColumn(\"pickup_day_of_week\", dayofweek(\"pickup_datetime\")) \\\n",
    "           .withColumn(\"pickup_month\", month(\"pickup_datetime\")) \\\n",
    "           .withColumn(\"pickup_day_of_year\", dayofyear(\"pickup_datetime\"))\n",
    "    \n",
    "    df = df.withColumn(\"hour_category\", \n",
    "                      when(col(\"pickup_hour\").between(6, 12), \"Morning\")\n",
    "                      .when(col(\"pickup_hour\").between(13, 18), \"Afternoon\") \n",
    "                      .when(col(\"pickup_hour\").between(19, 22), \"Evening\")\n",
    "                      .otherwise(\"Night\"))\n",
    "    \n",
    "    df = df.withColumn(\"is_weekend\", \n",
    "                      when(col(\"pickup_day_of_week\").isin([1, 7]), 1).otherwise(0))\n",
    "    \n",
    "    df = df.withColumn(\"calculated_distance\", \n",
    "                      calculate_haversine_distance(\n",
    "                          col(\"pickup_latitude\"), col(\"pickup_longitude\"),\n",
    "                          col(\"dropoff_latitude\"), col(\"dropoff_longitude\")))\n",
    "    \n",
    "    initial_count = df.count()\n",
    "    \n",
    "    df = df.filter(col(\"trip_duration_minutes\") > 0) \\\n",
    "           .filter(col(\"trip_duration_minutes\") < 180) \\\n",
    "           .filter(col(\"passenger_count\") > 0) \\\n",
    "           .filter(col(\"passenger_count\") <= 6) \\\n",
    "           .filter(col(\"trip_distance\") > 0) \\\n",
    "           .filter(col(\"trip_distance\") < 50) \\\n",
    "           .filter(col(\"pickup_latitude\").between(40.4, 41.0)) \\\n",
    "           .filter(col(\"pickup_longitude\").between(-74.3, -73.7)) \\\n",
    "           .filter(col(\"dropoff_latitude\").between(40.4, 41.0)) \\\n",
    "           .filter(col(\"dropoff_longitude\").between(-74.3, -73.7))\n",
    "    \n",
    "    final_count = df.count()\n",
    "    print(f\"Records after filtering: {final_count} (removed: {initial_count - final_count})\")\n",
    "    \n",
    "    df = df.withColumn(\"trip_category\",\n",
    "                      when(col(\"trip_duration_minutes\") <= 10, \"Short\")\n",
    "                      .when(col(\"trip_duration_minutes\") <= 30, \"Medium\")\n",
    "                      .otherwise(\"Long\"))\n",
    "    \n",
    "    df = df.withColumn(\"is_long_trip\", \n",
    "                      when(col(\"trip_duration_minutes\") > 20, 1.0).otherwise(0.0))\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_processed = preprocess_data(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f6b19d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPLORATORY DATA ANALYSIS\n",
      "==================================================\n",
      "\n",
      "Trip Duration Statistics:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------------+\n",
      "|summary|trip_duration_minutes|\n",
      "+-------+---------------------+\n",
      "|  count|             11937106|\n",
      "|   mean|   13.673365486017442|\n",
      "| stddev|   10.454997064136354|\n",
      "|    min| 0.016666666666666666|\n",
      "|    max|   179.63333333333333|\n",
      "+-------+---------------------+\n",
      "\n",
      "\n",
      "Trip Category Distribution:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------+\n",
      "|trip_category|  count|\n",
      "+-------------+-------+\n",
      "|       Medium|5708960|\n",
      "|        Short|5399060|\n",
      "|         Long| 829086|\n",
      "+-------------+-------+\n",
      "\n",
      "\n",
      "Average Duration by Hour:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+----------+\n",
      "|pickup_hour|      avg_duration|trip_count|\n",
      "+-----------+------------------+----------+\n",
      "|          0|12.752213704866902|    419666|\n",
      "|          1|12.776843214230256|    300580|\n",
      "|          2|11.503745206805428|    188027|\n",
      "|          3|11.656112473601748|    176148|\n",
      "|          4|12.251764408224137|    125160|\n",
      "|          5|11.809048572256774|    121894|\n",
      "|          6|11.384076072352196|    270418|\n",
      "|          7|12.432140464444485|    459732|\n",
      "|          8|13.784295976064938|    561631|\n",
      "|          9|13.930470123624328|    560030|\n",
      "|         10|13.995830316589045|    537279|\n",
      "|         11| 14.19687779314925|    550081|\n",
      "|         12|14.204344865576635|    576673|\n",
      "|         13|14.404576607820777|    577837|\n",
      "|         14|15.243962770787855|    603809|\n",
      "|         15|15.569020053570203|    586396|\n",
      "|         16|15.471575336468138|    532938|\n",
      "|         17|14.995256439712275|    635458|\n",
      "|         18|13.874890487597169|    752274|\n",
      "|         19|12.903943260910784|    756210|\n",
      "+-----------+------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "\n",
      "Average Duration by Day of Week:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+----------+\n",
      "|pickup_day_of_week|      avg_duration|trip_count|\n",
      "+------------------+------------------+----------+\n",
      "|                 1| 12.64893460540238|   1448978|\n",
      "|                 2|13.348102517711938|   1390641|\n",
      "|                 3|13.715500564562475|   1833573|\n",
      "|                 4| 14.18349718853027|   1915309|\n",
      "|                 5|14.577880846312045|   1991070|\n",
      "|                 6| 14.02597495567632|   1658819|\n",
      "|                 7|12.788294384307413|   1698716|\n",
      "+------------------+------------------+----------+\n",
      "\n",
      "\n",
      "Average Duration by Passenger Count:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------------+------------------+----------+\n",
      "|passenger_count|      avg_duration|      avg_distance|trip_count|\n",
      "+---------------+------------------+------------------+----------+\n",
      "|              1|13.474862508849416|2.8986088638699505|   8481758|\n",
      "|              2| 14.32388176098397|3.1536527257232687|   1695605|\n",
      "|              3|14.209151493976186| 3.045415419444609|    489421|\n",
      "|              4|14.588819098690495|  3.14508470024553|    234592|\n",
      "|              5|13.820332701637945| 3.054876866581224|    635855|\n",
      "|              6|13.698880233406294|2.9757775554860877|    399875|\n",
      "+---------------+------------------+------------------+----------+\n",
      "\n",
      "Features prepared: 12 total features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/22 12:45:27 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 8356184 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 31:=====================================================>  (19 + 1) / 20]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: 3580922 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Exploratory Data Analysis\n",
    "def exploratory_data_analysis(df):\n",
    "    print(\"EXPLORATORY DATA ANALYSIS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    print(\"\\nTrip Duration Statistics:\")\n",
    "    df.select(\"trip_duration_minutes\").describe().show()\n",
    "    \n",
    "    print(\"\\nTrip Category Distribution:\")\n",
    "    df.groupBy(\"trip_category\").count().orderBy(\"count\", ascending=False).show()\n",
    "    \n",
    "    print(\"\\nAverage Duration by Hour:\")\n",
    "    hourly_stats = df.groupBy(\"pickup_hour\") \\\n",
    "                     .agg(avg(\"trip_duration_minutes\").alias(\"avg_duration\"),\n",
    "                          count(\"*\").alias(\"trip_count\")) \\\n",
    "                     .orderBy(\"pickup_hour\")\n",
    "    hourly_stats.show()\n",
    "    \n",
    "    print(\"\\nAverage Duration by Day of Week:\")\n",
    "    daily_stats = df.groupBy(\"pickup_day_of_week\") \\\n",
    "                    .agg(avg(\"trip_duration_minutes\").alias(\"avg_duration\"),\n",
    "                         count(\"*\").alias(\"trip_count\")) \\\n",
    "                    .orderBy(\"pickup_day_of_week\")\n",
    "    daily_stats.show()\n",
    "    \n",
    "    print(\"\\nAverage Duration by Passenger Count:\")\n",
    "    passenger_stats = df.groupBy(\"passenger_count\") \\\n",
    "                        .agg(avg(\"trip_duration_minutes\").alias(\"avg_duration\"),\n",
    "                             avg(\"trip_distance\").alias(\"avg_distance\"),\n",
    "                             count(\"*\").alias(\"trip_count\")) \\\n",
    "                        .orderBy(\"passenger_count\")\n",
    "    passenger_stats.show()\n",
    "\n",
    "exploratory_data_analysis(df_processed)\n",
    "\n",
    "# Feature Preparation\n",
    "def prepare_features_for_ml(df):\n",
    "    numeric_features = [\n",
    "        \"pickup_hour\", \"pickup_day_of_week\", \"pickup_month\", \n",
    "        \"is_weekend\", \"passenger_count\", \"trip_distance\", \n",
    "        \"calculated_distance\", \"pickup_longitude\", \"pickup_latitude\",\n",
    "        \"dropoff_longitude\", \"dropoff_latitude\"\n",
    "    ]\n",
    "    \n",
    "    categorical_features = [\"hour_category\"]\n",
    "    \n",
    "    indexers = []\n",
    "    for cat_col in categorical_features:\n",
    "        indexer = StringIndexer(inputCol=cat_col, outputCol=f\"{cat_col}_index\", handleInvalid=\"keep\")\n",
    "        indexers.append(indexer)\n",
    "    \n",
    "    encoders = []\n",
    "    encoded_cols = []\n",
    "    for cat_col in categorical_features:\n",
    "        encoder = OneHotEncoder(inputCol=f\"{cat_col}_index\", outputCol=f\"{cat_col}_encoded\")\n",
    "        encoders.append(encoder)\n",
    "        encoded_cols.append(f\"{cat_col}_encoded\")\n",
    "    \n",
    "    all_feature_cols = numeric_features + encoded_cols\n",
    "    \n",
    "    assembler = VectorAssembler(\n",
    "        inputCols=all_feature_cols, \n",
    "        outputCol=\"features\", \n",
    "        handleInvalid=\"skip\"\n",
    "    )\n",
    "    \n",
    "    print(f\"Features prepared: {len(all_feature_cols)} total features\")\n",
    "    \n",
    "    return indexers, encoders, assembler\n",
    "\n",
    "indexers, encoders, assembler = prepare_features_for_ml(df_processed)\n",
    "\n",
    "#  Data Pipeline and Split\n",
    "def create_preprocessing_pipeline_and_split_data(df, indexers, encoders, assembler):\n",
    "    preprocessing_stages = indexers + encoders + [assembler]\n",
    "    preprocessing_pipeline = Pipeline(stages=preprocessing_stages)\n",
    "    \n",
    "    preprocessing_model = preprocessing_pipeline.fit(df)\n",
    "    df_features = preprocessing_model.transform(df)\n",
    "    \n",
    "    train_data, test_data = df_features.randomSplit([0.7, 0.3], seed=42)\n",
    "    \n",
    "    print(f\"Training set: {train_data.count()} records\")\n",
    "    print(f\"Test set: {test_data.count()} records\")\n",
    "    \n",
    "    return train_data, test_data, preprocessing_model\n",
    "\n",
    "train_data, test_data, preprocessing_model = create_preprocessing_pipeline_and_split_data(\n",
    "    df_processed, indexers, encoders, assembler\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5c2a25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REGRESSION MODELS TRAINING\n",
      "==================================================\n",
      "\n",
      "1. Linear Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/22 12:46:06 WARN Instrumentation: [7d4f1755] regParam is zero, which might cause numerical instability and overfitting.\n",
      "25/05/22 12:46:22 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n",
      "25/05/22 12:46:25 WARN Instrumentation: [7d4f1755] Cholesky solver failed due to singular covariance matrix. Retrying with Quasi-Newton solver.\n",
      "25/05/22 12:46:25 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search zoom failed\n",
      "25/05/22 12:46:25 ERROR LBFGS: Failure again! Giving up and returning. Maybe the objective is just poorly behaved?\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RMSE: 5.999, MAE: 4.090, R²: 0.670\n",
      "\n",
      "2. Random Forest Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/22 12:48:33 WARN MemoryStore: Not enough space to cache rdd_193_6 in memory! (computed 28.7 MiB so far)\n",
      "25/05/22 12:48:33 WARN MemoryStore: Not enough space to cache rdd_193_18 in memory! (computed 5.3 MiB so far)\n",
      "25/05/22 12:48:33 WARN BlockManager: Persisting block rdd_193_6 to disk instead.\n",
      "25/05/22 12:48:33 WARN BlockManager: Persisting block rdd_193_18 to disk instead.\n",
      "25/05/22 12:48:33 WARN MemoryStore: Not enough space to cache rdd_193_15 in memory! (computed 43.1 MiB so far)\n",
      "25/05/22 12:48:33 WARN BlockManager: Persisting block rdd_193_15 to disk instead.\n",
      "25/05/22 12:48:33 WARN MemoryStore: Not enough space to cache rdd_193_3 in memory! (computed 43.1 MiB so far)\n",
      "25/05/22 12:48:33 WARN BlockManager: Persisting block rdd_193_3 to disk instead.\n",
      "25/05/22 12:48:33 WARN MemoryStore: Not enough space to cache rdd_193_2 in memory! (computed 43.1 MiB so far)\n",
      "25/05/22 12:48:33 WARN MemoryStore: Not enough space to cache rdd_193_16 in memory! (computed 43.1 MiB so far)\n",
      "25/05/22 12:48:33 WARN BlockManager: Persisting block rdd_193_16 to disk instead.\n",
      "25/05/22 12:48:33 WARN BlockManager: Persisting block rdd_193_2 to disk instead.\n",
      "25/05/22 12:48:33 WARN MemoryStore: Not enough space to cache rdd_193_9 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:48:33 WARN BlockManager: Persisting block rdd_193_9 to disk instead.\n",
      "25/05/22 12:48:33 WARN MemoryStore: Not enough space to cache rdd_193_13 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:48:33 WARN BlockManager: Persisting block rdd_193_13 to disk instead.\n",
      "25/05/22 12:48:34 WARN MemoryStore: Not enough space to cache rdd_193_10 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:48:34 WARN BlockManager: Persisting block rdd_193_10 to disk instead.\n",
      "25/05/22 12:48:34 WARN MemoryStore: Not enough space to cache rdd_193_17 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:48:34 WARN BlockManager: Persisting block rdd_193_17 to disk instead.\n",
      "25/05/22 12:48:34 WARN MemoryStore: Not enough space to cache rdd_193_1 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:48:34 WARN BlockManager: Persisting block rdd_193_1 to disk instead.\n",
      "25/05/22 12:48:34 WARN MemoryStore: Not enough space to cache rdd_193_19 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:48:34 WARN BlockManager: Persisting block rdd_193_19 to disk instead.\n",
      "25/05/22 12:48:34 WARN MemoryStore: Not enough space to cache rdd_193_5 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:48:34 WARN BlockManager: Persisting block rdd_193_5 to disk instead.\n",
      "25/05/22 12:48:34 WARN MemoryStore: Not enough space to cache rdd_193_14 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:48:34 WARN BlockManager: Persisting block rdd_193_14 to disk instead.\n",
      "25/05/22 12:48:34 WARN MemoryStore: Not enough space to cache rdd_193_11 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:48:34 WARN BlockManager: Persisting block rdd_193_11 to disk instead.\n",
      "25/05/22 12:48:34 WARN MemoryStore: Not enough space to cache rdd_193_0 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:48:34 WARN BlockManager: Persisting block rdd_193_0 to disk instead.\n",
      "25/05/22 12:48:34 WARN MemoryStore: Not enough space to cache rdd_193_8 in memory! (computed 101.0 MiB so far)\n",
      "25/05/22 12:48:34 WARN BlockManager: Persisting block rdd_193_8 to disk instead.\n",
      "25/05/22 12:48:38 WARN MemoryStore: Not enough space to cache rdd_193_9 in memory! (computed 101.0 MiB so far)\n",
      "25/05/22 12:48:38 WARN MemoryStore: Not enough space to cache rdd_193_11 in memory! (computed 101.0 MiB so far)\n",
      "25/05/22 12:48:38 WARN MemoryStore: Not enough space to cache rdd_193_1 in memory! (computed 101.0 MiB so far)\n",
      "25/05/22 12:48:38 WARN MemoryStore: Not enough space to cache rdd_193_3 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:48:38 WARN MemoryStore: Not enough space to cache rdd_193_0 in memory! (computed 28.7 MiB so far)\n",
      "25/05/22 12:48:38 WARN MemoryStore: Not enough space to cache rdd_193_2 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:48:38 WARN MemoryStore: Not enough space to cache rdd_193_16 in memory! (computed 43.1 MiB so far)\n",
      "25/05/22 12:48:38 WARN MemoryStore: Not enough space to cache rdd_193_6 in memory! (computed 43.1 MiB so far)\n",
      "25/05/22 12:48:41 WARN MemoryStore: Not enough space to cache rdd_193_9 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:48:41 WARN MemoryStore: Not enough space to cache rdd_193_0 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:48:41 WARN MemoryStore: Not enough space to cache rdd_193_1 in memory! (computed 43.1 MiB so far)\n",
      "25/05/22 12:48:41 WARN MemoryStore: Not enough space to cache rdd_193_2 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:48:41 WARN MemoryStore: Not enough space to cache rdd_193_16 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:48:41 WARN MemoryStore: Not enough space to cache rdd_193_6 in memory! (computed 101.0 MiB so far)\n",
      "25/05/22 12:48:41 WARN MemoryStore: Not enough space to cache rdd_193_11 in memory! (computed 101.0 MiB so far)\n",
      "25/05/22 12:48:41 WARN MemoryStore: Not enough space to cache rdd_193_3 in memory! (computed 43.1 MiB so far)\n",
      "25/05/22 12:48:46 WARN MemoryStore: Not enough space to cache rdd_193_11 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:48:46 WARN MemoryStore: Not enough space to cache rdd_193_3 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:48:46 WARN MemoryStore: Not enough space to cache rdd_193_16 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:48:46 WARN MemoryStore: Not enough space to cache rdd_193_6 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:48:46 WARN MemoryStore: Not enough space to cache rdd_193_9 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:48:46 WARN MemoryStore: Not enough space to cache rdd_193_0 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:48:46 WARN MemoryStore: Not enough space to cache rdd_193_1 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:48:46 WARN MemoryStore: Not enough space to cache rdd_193_2 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:48:51 WARN MemoryStore: Not enough space to cache rdd_193_16 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:48:51 WARN MemoryStore: Not enough space to cache rdd_193_3 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:48:51 WARN MemoryStore: Not enough space to cache rdd_193_0 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:48:51 WARN MemoryStore: Not enough space to cache rdd_193_9 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:48:51 WARN MemoryStore: Not enough space to cache rdd_193_2 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:48:51 WARN MemoryStore: Not enough space to cache rdd_193_6 in memory! (computed 43.1 MiB so far)\n",
      "25/05/22 12:48:51 WARN MemoryStore: Not enough space to cache rdd_193_11 in memory! (computed 101.0 MiB so far)\n",
      "25/05/22 12:48:51 WARN MemoryStore: Not enough space to cache rdd_193_1 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:48:57 WARN MemoryStore: Not enough space to cache rdd_193_9 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:48:57 WARN MemoryStore: Not enough space to cache rdd_193_1 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:48:57 WARN MemoryStore: Not enough space to cache rdd_193_11 in memory! (computed 43.1 MiB so far)\n",
      "25/05/22 12:48:57 WARN MemoryStore: Not enough space to cache rdd_193_0 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:48:57 WARN MemoryStore: Not enough space to cache rdd_193_6 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:48:57 WARN MemoryStore: Not enough space to cache rdd_193_2 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:48:57 WARN MemoryStore: Not enough space to cache rdd_193_16 in memory! (computed 101.0 MiB so far)\n",
      "25/05/22 12:48:57 WARN MemoryStore: Not enough space to cache rdd_193_3 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:49:05 WARN MemoryStore: Not enough space to cache rdd_193_6 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:49:05 WARN MemoryStore: Not enough space to cache rdd_193_1 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:49:05 WARN MemoryStore: Not enough space to cache rdd_193_0 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:49:05 WARN MemoryStore: Not enough space to cache rdd_193_2 in memory! (computed 43.1 MiB so far)\n",
      "25/05/22 12:49:05 WARN MemoryStore: Not enough space to cache rdd_193_9 in memory! (computed 43.1 MiB so far)\n",
      "25/05/22 12:49:05 WARN MemoryStore: Not enough space to cache rdd_193_16 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:49:05 WARN MemoryStore: Not enough space to cache rdd_193_11 in memory! (computed 101.0 MiB so far)\n",
      "25/05/22 12:49:06 WARN MemoryStore: Not enough space to cache rdd_193_3 in memory! (computed 101.0 MiB so far)\n",
      "25/05/22 12:49:16 WARN DAGScheduler: Broadcasting large task binary with size 1166.8 KiB\n",
      "25/05/22 12:49:16 WARN MemoryStore: Not enough space to cache rdd_193_11 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:49:16 WARN MemoryStore: Not enough space to cache rdd_193_2 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:49:16 WARN MemoryStore: Not enough space to cache rdd_193_1 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:49:16 WARN MemoryStore: Not enough space to cache rdd_193_0 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:49:16 WARN MemoryStore: Not enough space to cache rdd_193_3 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:49:16 WARN MemoryStore: Not enough space to cache rdd_193_16 in memory! (computed 43.1 MiB so far)\n",
      "25/05/22 12:49:16 WARN MemoryStore: Not enough space to cache rdd_193_9 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:49:16 WARN MemoryStore: Not enough space to cache rdd_193_6 in memory! (computed 101.0 MiB so far)\n",
      "25/05/22 12:49:31 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "25/05/22 12:49:31 WARN MemoryStore: Not enough space to cache rdd_193_16 in memory! (computed 43.1 MiB so far)\n",
      "25/05/22 12:49:32 WARN MemoryStore: Not enough space to cache rdd_193_2 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:49:32 WARN MemoryStore: Not enough space to cache rdd_193_3 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:49:32 WARN MemoryStore: Not enough space to cache rdd_193_9 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:49:32 WARN MemoryStore: Not enough space to cache rdd_193_11 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:49:32 WARN MemoryStore: Not enough space to cache rdd_193_0 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:49:32 WARN MemoryStore: Not enough space to cache rdd_193_6 in memory! (computed 101.0 MiB so far)\n",
      "25/05/22 12:49:32 WARN MemoryStore: Not enough space to cache rdd_193_1 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:49:54 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "25/05/22 12:49:55 WARN MemoryStore: Not enough space to cache rdd_193_3 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:49:55 WARN MemoryStore: Not enough space to cache rdd_193_16 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:49:55 WARN MemoryStore: Not enough space to cache rdd_193_9 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:49:55 WARN MemoryStore: Not enough space to cache rdd_193_6 in memory! (computed 43.1 MiB so far)\n",
      "25/05/22 12:49:55 WARN MemoryStore: Not enough space to cache rdd_193_0 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:49:55 WARN MemoryStore: Not enough space to cache rdd_193_2 in memory! (computed 101.0 MiB so far)\n",
      "25/05/22 12:49:55 WARN MemoryStore: Not enough space to cache rdd_193_11 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:49:55 WARN MemoryStore: Not enough space to cache rdd_193_1 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:50:26 WARN DAGScheduler: Broadcasting large task binary with size 1231.3 KiB\n",
      "25/05/22 12:50:27 WARN DAGScheduler: Broadcasting large task binary with size 7.9 MiB\n",
      "25/05/22 12:50:28 WARN MemoryStore: Not enough space to cache rdd_193_11 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:50:28 WARN MemoryStore: Not enough space to cache rdd_193_1 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:50:28 WARN MemoryStore: Not enough space to cache rdd_193_16 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:50:28 WARN MemoryStore: Not enough space to cache rdd_193_9 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:50:28 WARN MemoryStore: Not enough space to cache rdd_193_6 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:50:28 WARN MemoryStore: Not enough space to cache rdd_193_0 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:50:28 WARN MemoryStore: Not enough space to cache rdd_193_3 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:50:29 WARN MemoryStore: Not enough space to cache rdd_193_2 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 12:51:14 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RMSE: 4.752, MAE: 3.022, R²: 0.793\n",
      "   Top 5 Feature Importances:\n",
      "     Feature 0: 0.0332\n",
      "     Feature 1: 0.0058\n",
      "     Feature 2: 0.0000\n",
      "     Feature 3: 0.0100\n",
      "     Feature 4: 0.0001\n",
      "\n",
      "3. Gradient Boosted Trees\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/22 12:54:19 WARN DAGScheduler: Broadcasting large task binary with size 1001.7 KiB\n",
      "25/05/22 12:54:19 WARN DAGScheduler: Broadcasting large task binary with size 1006.3 KiB\n",
      "25/05/22 12:54:20 WARN DAGScheduler: Broadcasting large task binary with size 1015.5 KiB\n",
      "25/05/22 12:54:20 WARN DAGScheduler: Broadcasting large task binary with size 1034.4 KiB\n",
      "25/05/22 12:54:20 WARN DAGScheduler: Broadcasting large task binary with size 1041.4 KiB\n",
      "25/05/22 12:54:22 WARN DAGScheduler: Broadcasting large task binary with size 1041.9 KiB\n",
      "25/05/22 12:54:22 WARN DAGScheduler: Broadcasting large task binary with size 1042.5 KiB\n",
      "25/05/22 12:54:22 WARN DAGScheduler: Broadcasting large task binary with size 1043.6 KiB\n",
      "25/05/22 12:54:22 WARN DAGScheduler: Broadcasting large task binary with size 1045.9 KiB\n",
      "25/05/22 12:54:23 WARN DAGScheduler: Broadcasting large task binary with size 1050.4 KiB\n",
      "25/05/22 12:54:23 WARN DAGScheduler: Broadcasting large task binary with size 1059.6 KiB\n",
      "25/05/22 12:54:23 WARN DAGScheduler: Broadcasting large task binary with size 1078.4 KiB\n",
      "25/05/22 12:54:24 WARN DAGScheduler: Broadcasting large task binary with size 1085.5 KiB\n",
      "25/05/22 12:54:26 WARN DAGScheduler: Broadcasting large task binary with size 1086.0 KiB\n",
      "25/05/22 12:54:26 WARN DAGScheduler: Broadcasting large task binary with size 1086.6 KiB\n",
      "25/05/22 12:54:26 WARN DAGScheduler: Broadcasting large task binary with size 1087.7 KiB\n",
      "25/05/22 12:54:26 WARN DAGScheduler: Broadcasting large task binary with size 1090.0 KiB\n",
      "25/05/22 12:54:27 WARN DAGScheduler: Broadcasting large task binary with size 1094.5 KiB\n",
      "25/05/22 12:54:27 WARN DAGScheduler: Broadcasting large task binary with size 1103.6 KiB\n",
      "25/05/22 12:54:27 WARN DAGScheduler: Broadcasting large task binary with size 1122.4 KiB\n",
      "25/05/22 12:54:28 WARN DAGScheduler: Broadcasting large task binary with size 1129.0 KiB\n",
      "25/05/22 12:54:29 WARN DAGScheduler: Broadcasting large task binary with size 1129.5 KiB\n",
      "25/05/22 12:54:29 WARN DAGScheduler: Broadcasting large task binary with size 1130.0 KiB\n",
      "25/05/22 12:54:29 WARN DAGScheduler: Broadcasting large task binary with size 1131.2 KiB\n",
      "25/05/22 12:54:30 WARN DAGScheduler: Broadcasting large task binary with size 1133.4 KiB\n",
      "25/05/22 12:54:30 WARN DAGScheduler: Broadcasting large task binary with size 1138.0 KiB\n",
      "25/05/22 12:54:30 WARN DAGScheduler: Broadcasting large task binary with size 1147.1 KiB\n",
      "25/05/22 12:54:31 WARN DAGScheduler: Broadcasting large task binary with size 1165.6 KiB\n",
      "25/05/22 12:54:31 WARN DAGScheduler: Broadcasting large task binary with size 1171.6 KiB\n",
      "25/05/22 12:54:33 WARN DAGScheduler: Broadcasting large task binary with size 1172.1 KiB\n",
      "25/05/22 12:54:33 WARN DAGScheduler: Broadcasting large task binary with size 1172.6 KiB\n",
      "25/05/22 12:54:33 WARN DAGScheduler: Broadcasting large task binary with size 1173.8 KiB\n",
      "25/05/22 12:54:33 WARN DAGScheduler: Broadcasting large task binary with size 1176.0 KiB\n",
      "25/05/22 12:54:34 WARN DAGScheduler: Broadcasting large task binary with size 1180.6 KiB\n",
      "25/05/22 12:54:34 WARN DAGScheduler: Broadcasting large task binary with size 1189.8 KiB\n",
      "25/05/22 12:54:34 WARN DAGScheduler: Broadcasting large task binary with size 1208.5 KiB\n",
      "25/05/22 12:54:35 WARN DAGScheduler: Broadcasting large task binary with size 1215.0 KiB\n",
      "25/05/22 12:54:36 WARN DAGScheduler: Broadcasting large task binary with size 1215.5 KiB\n",
      "25/05/22 12:54:37 WARN DAGScheduler: Broadcasting large task binary with size 1216.0 KiB\n",
      "25/05/22 12:54:37 WARN DAGScheduler: Broadcasting large task binary with size 1217.2 KiB\n",
      "25/05/22 12:54:37 WARN DAGScheduler: Broadcasting large task binary with size 1219.4 KiB\n",
      "25/05/22 12:54:38 WARN DAGScheduler: Broadcasting large task binary with size 1224.0 KiB\n",
      "25/05/22 12:54:38 WARN DAGScheduler: Broadcasting large task binary with size 1233.2 KiB\n",
      "25/05/22 12:54:38 WARN DAGScheduler: Broadcasting large task binary with size 1252.2 KiB\n",
      "25/05/22 12:54:39 WARN DAGScheduler: Broadcasting large task binary with size 1259.0 KiB\n",
      "25/05/22 12:54:40 WARN DAGScheduler: Broadcasting large task binary with size 1259.5 KiB\n",
      "25/05/22 12:54:40 WARN DAGScheduler: Broadcasting large task binary with size 1260.1 KiB\n",
      "25/05/22 12:54:41 WARN DAGScheduler: Broadcasting large task binary with size 1261.2 KiB\n",
      "25/05/22 12:54:41 WARN DAGScheduler: Broadcasting large task binary with size 1263.6 KiB\n",
      "25/05/22 12:54:41 WARN DAGScheduler: Broadcasting large task binary with size 1268.1 KiB\n",
      "25/05/22 12:54:42 WARN DAGScheduler: Broadcasting large task binary with size 1277.2 KiB\n",
      "25/05/22 12:54:42 WARN DAGScheduler: Broadcasting large task binary with size 1295.9 KiB\n",
      "25/05/22 12:54:42 WARN DAGScheduler: Broadcasting large task binary with size 1302.4 KiB\n",
      "25/05/22 12:54:44 WARN DAGScheduler: Broadcasting large task binary with size 1302.9 KiB\n",
      "25/05/22 12:54:44 WARN DAGScheduler: Broadcasting large task binary with size 1303.5 KiB\n",
      "25/05/22 12:54:44 WARN DAGScheduler: Broadcasting large task binary with size 1304.6 KiB\n",
      "25/05/22 12:54:45 WARN DAGScheduler: Broadcasting large task binary with size 1306.9 KiB\n",
      "25/05/22 12:54:45 WARN DAGScheduler: Broadcasting large task binary with size 1311.4 KiB\n",
      "25/05/22 12:54:45 WARN DAGScheduler: Broadcasting large task binary with size 1320.5 KiB\n",
      "25/05/22 12:54:46 WARN DAGScheduler: Broadcasting large task binary with size 1339.3 KiB\n",
      "25/05/22 12:54:46 WARN DAGScheduler: Broadcasting large task binary with size 1345.8 KiB\n",
      "25/05/22 12:54:48 WARN DAGScheduler: Broadcasting large task binary with size 1346.3 KiB\n",
      "25/05/22 12:54:48 WARN DAGScheduler: Broadcasting large task binary with size 1346.8 KiB\n",
      "25/05/22 12:54:48 WARN DAGScheduler: Broadcasting large task binary with size 1348.0 KiB\n",
      "25/05/22 12:54:48 WARN DAGScheduler: Broadcasting large task binary with size 1350.2 KiB\n",
      "25/05/22 12:54:49 WARN DAGScheduler: Broadcasting large task binary with size 1354.8 KiB\n",
      "25/05/22 12:54:49 WARN DAGScheduler: Broadcasting large task binary with size 1363.8 KiB\n",
      "25/05/22 12:54:50 WARN DAGScheduler: Broadcasting large task binary with size 1381.7 KiB\n",
      "25/05/22 12:54:50 WARN DAGScheduler: Broadcasting large task binary with size 1387.5 KiB\n",
      "25/05/22 12:54:52 WARN DAGScheduler: Broadcasting large task binary with size 1388.0 KiB\n",
      "25/05/22 12:54:52 WARN DAGScheduler: Broadcasting large task binary with size 1388.6 KiB\n",
      "25/05/22 12:54:53 WARN DAGScheduler: Broadcasting large task binary with size 1389.7 KiB\n",
      "25/05/22 12:54:53 WARN DAGScheduler: Broadcasting large task binary with size 1392.0 KiB\n",
      "25/05/22 12:54:53 WARN DAGScheduler: Broadcasting large task binary with size 1396.5 KiB\n",
      "25/05/22 12:54:54 WARN DAGScheduler: Broadcasting large task binary with size 1405.6 KiB\n",
      "25/05/22 12:54:54 WARN DAGScheduler: Broadcasting large task binary with size 1424.5 KiB\n",
      "25/05/22 12:54:55 WARN DAGScheduler: Broadcasting large task binary with size 1431.4 KiB\n",
      "25/05/22 12:54:56 WARN DAGScheduler: Broadcasting large task binary with size 1431.9 KiB\n",
      "25/05/22 12:54:56 WARN DAGScheduler: Broadcasting large task binary with size 1432.4 KiB\n",
      "25/05/22 12:54:56 WARN DAGScheduler: Broadcasting large task binary with size 1433.6 KiB\n",
      "25/05/22 12:54:57 WARN DAGScheduler: Broadcasting large task binary with size 1435.8 KiB\n",
      "25/05/22 12:54:57 WARN DAGScheduler: Broadcasting large task binary with size 1440.4 KiB\n",
      "25/05/22 12:54:57 WARN DAGScheduler: Broadcasting large task binary with size 1449.4 KiB\n",
      "25/05/22 12:54:58 WARN DAGScheduler: Broadcasting large task binary with size 1468.4 KiB\n",
      "25/05/22 12:54:58 WARN DAGScheduler: Broadcasting large task binary with size 1475.3 KiB\n",
      "25/05/22 12:55:00 WARN DAGScheduler: Broadcasting large task binary with size 1475.8 KiB\n",
      "25/05/22 12:55:00 WARN DAGScheduler: Broadcasting large task binary with size 1476.3 KiB\n",
      "25/05/22 12:55:00 WARN DAGScheduler: Broadcasting large task binary with size 1477.5 KiB\n",
      "25/05/22 12:55:01 WARN DAGScheduler: Broadcasting large task binary with size 1479.7 KiB\n",
      "25/05/22 12:55:01 WARN DAGScheduler: Broadcasting large task binary with size 1484.3 KiB\n",
      "25/05/22 12:55:01 WARN DAGScheduler: Broadcasting large task binary with size 1493.4 KiB\n",
      "25/05/22 12:55:01 WARN DAGScheduler: Broadcasting large task binary with size 1512.2 KiB\n",
      "25/05/22 12:55:02 WARN DAGScheduler: Broadcasting large task binary with size 1518.9 KiB\n",
      "25/05/22 12:55:03 WARN DAGScheduler: Broadcasting large task binary with size 1519.4 KiB\n",
      "25/05/22 12:55:04 WARN DAGScheduler: Broadcasting large task binary with size 1520.0 KiB\n",
      "25/05/22 12:55:04 WARN DAGScheduler: Broadcasting large task binary with size 1521.1 KiB\n",
      "25/05/22 12:55:04 WARN DAGScheduler: Broadcasting large task binary with size 1523.5 KiB\n",
      "25/05/22 12:55:04 WARN DAGScheduler: Broadcasting large task binary with size 1528.1 KiB\n",
      "25/05/22 12:55:05 WARN DAGScheduler: Broadcasting large task binary with size 1537.2 KiB\n",
      "25/05/22 12:55:05 WARN DAGScheduler: Broadcasting large task binary with size 1556.0 KiB\n",
      "25/05/22 12:55:05 WARN DAGScheduler: Broadcasting large task binary with size 1562.4 KiB\n",
      "25/05/22 12:55:07 WARN DAGScheduler: Broadcasting large task binary with size 1562.9 KiB\n",
      "25/05/22 12:55:07 WARN DAGScheduler: Broadcasting large task binary with size 1563.5 KiB\n",
      "25/05/22 12:55:07 WARN DAGScheduler: Broadcasting large task binary with size 1564.6 KiB\n",
      "25/05/22 12:55:08 WARN DAGScheduler: Broadcasting large task binary with size 1566.9 KiB\n",
      "25/05/22 12:55:08 WARN DAGScheduler: Broadcasting large task binary with size 1571.4 KiB\n",
      "25/05/22 12:55:08 WARN DAGScheduler: Broadcasting large task binary with size 1580.5 KiB\n",
      "25/05/22 12:55:09 WARN DAGScheduler: Broadcasting large task binary with size 1599.5 KiB\n",
      "25/05/22 12:55:09 WARN DAGScheduler: Broadcasting large task binary with size 1606.1 KiB\n",
      "25/05/22 12:55:10 WARN DAGScheduler: Broadcasting large task binary with size 1606.6 KiB\n",
      "25/05/22 12:55:11 WARN DAGScheduler: Broadcasting large task binary with size 1607.2 KiB\n",
      "25/05/22 12:55:11 WARN DAGScheduler: Broadcasting large task binary with size 1608.3 KiB\n",
      "25/05/22 12:55:11 WARN DAGScheduler: Broadcasting large task binary with size 1610.6 KiB\n",
      "25/05/22 12:55:12 WARN DAGScheduler: Broadcasting large task binary with size 1615.2 KiB\n",
      "25/05/22 12:55:12 WARN DAGScheduler: Broadcasting large task binary with size 1624.4 KiB\n",
      "25/05/22 12:55:12 WARN DAGScheduler: Broadcasting large task binary with size 1643.1 KiB\n",
      "25/05/22 12:55:13 WARN DAGScheduler: Broadcasting large task binary with size 1649.1 KiB\n",
      "25/05/22 12:55:14 WARN DAGScheduler: Broadcasting large task binary with size 1649.6 KiB\n",
      "25/05/22 12:55:14 WARN DAGScheduler: Broadcasting large task binary with size 1650.1 KiB\n",
      "25/05/22 12:55:15 WARN DAGScheduler: Broadcasting large task binary with size 1651.3 KiB\n",
      "25/05/22 12:55:15 WARN DAGScheduler: Broadcasting large task binary with size 1653.5 KiB\n",
      "25/05/22 12:55:15 WARN DAGScheduler: Broadcasting large task binary with size 1658.1 KiB\n",
      "25/05/22 12:55:16 WARN DAGScheduler: Broadcasting large task binary with size 1667.3 KiB\n",
      "25/05/22 12:55:16 WARN DAGScheduler: Broadcasting large task binary with size 1686.0 KiB\n",
      "25/05/22 12:55:16 WARN DAGScheduler: Broadcasting large task binary with size 1692.2 KiB\n",
      "25/05/22 12:55:18 WARN DAGScheduler: Broadcasting large task binary with size 1692.7 KiB\n",
      "25/05/22 12:55:18 WARN DAGScheduler: Broadcasting large task binary with size 1693.2 KiB\n",
      "25/05/22 12:55:18 WARN DAGScheduler: Broadcasting large task binary with size 1694.4 KiB\n",
      "25/05/22 12:55:19 WARN DAGScheduler: Broadcasting large task binary with size 1696.6 KiB\n",
      "25/05/22 12:55:19 WARN DAGScheduler: Broadcasting large task binary with size 1701.2 KiB\n",
      "25/05/22 12:55:19 WARN DAGScheduler: Broadcasting large task binary with size 1710.4 KiB\n",
      "25/05/22 12:55:20 WARN DAGScheduler: Broadcasting large task binary with size 1729.1 KiB\n",
      "25/05/22 12:55:20 WARN DAGScheduler: Broadcasting large task binary with size 1736.0 KiB\n",
      "25/05/22 12:55:22 WARN DAGScheduler: Broadcasting large task binary with size 1736.5 KiB\n",
      "25/05/22 12:55:22 WARN DAGScheduler: Broadcasting large task binary with size 1737.0 KiB\n",
      "25/05/22 12:55:22 WARN DAGScheduler: Broadcasting large task binary with size 1738.2 KiB\n",
      "25/05/22 12:55:22 WARN DAGScheduler: Broadcasting large task binary with size 1740.5 KiB\n",
      "25/05/22 12:55:23 WARN DAGScheduler: Broadcasting large task binary with size 1745.0 KiB\n",
      "25/05/22 12:55:23 WARN DAGScheduler: Broadcasting large task binary with size 1754.2 KiB\n",
      "25/05/22 12:55:23 WARN DAGScheduler: Broadcasting large task binary with size 1773.1 KiB\n",
      "25/05/22 12:55:24 WARN DAGScheduler: Broadcasting large task binary with size 1780.1 KiB\n",
      "25/05/22 12:55:25 WARN DAGScheduler: Broadcasting large task binary with size 1780.6 KiB\n",
      "25/05/22 12:55:26 WARN DAGScheduler: Broadcasting large task binary with size 1781.2 KiB\n",
      "25/05/22 12:55:26 WARN DAGScheduler: Broadcasting large task binary with size 1782.3 KiB\n",
      "25/05/22 12:55:26 WARN DAGScheduler: Broadcasting large task binary with size 1784.6 KiB\n",
      "25/05/22 12:55:26 WARN DAGScheduler: Broadcasting large task binary with size 1789.1 KiB\n",
      "25/05/22 12:55:27 WARN DAGScheduler: Broadcasting large task binary with size 1798.3 KiB\n",
      "25/05/22 12:55:27 WARN DAGScheduler: Broadcasting large task binary with size 1817.2 KiB\n",
      "25/05/22 12:55:28 WARN DAGScheduler: Broadcasting large task binary with size 1824.2 KiB\n",
      "25/05/22 12:55:29 WARN DAGScheduler: Broadcasting large task binary with size 1824.7 KiB\n",
      "25/05/22 12:55:29 WARN DAGScheduler: Broadcasting large task binary with size 1825.3 KiB\n",
      "25/05/22 12:55:30 WARN DAGScheduler: Broadcasting large task binary with size 1826.4 KiB\n",
      "25/05/22 12:55:30 WARN DAGScheduler: Broadcasting large task binary with size 1828.7 KiB\n",
      "25/05/22 12:55:30 WARN DAGScheduler: Broadcasting large task binary with size 1833.3 KiB\n",
      "25/05/22 12:55:31 WARN DAGScheduler: Broadcasting large task binary with size 1842.4 KiB\n",
      "25/05/22 12:55:31 WARN DAGScheduler: Broadcasting large task binary with size 1861.2 KiB\n",
      "25/05/22 12:55:31 WARN DAGScheduler: Broadcasting large task binary with size 1867.8 KiB\n",
      "25/05/22 12:55:33 WARN DAGScheduler: Broadcasting large task binary with size 1868.2 KiB\n",
      "25/05/22 12:55:33 WARN DAGScheduler: Broadcasting large task binary with size 1868.8 KiB\n",
      "25/05/22 12:55:33 WARN DAGScheduler: Broadcasting large task binary with size 1869.9 KiB\n",
      "25/05/22 12:55:34 WARN DAGScheduler: Broadcasting large task binary with size 1872.2 KiB\n",
      "25/05/22 12:55:34 WARN DAGScheduler: Broadcasting large task binary with size 1876.8 KiB\n",
      "25/05/22 12:55:34 WARN DAGScheduler: Broadcasting large task binary with size 1885.9 KiB\n",
      "25/05/22 12:55:34 WARN DAGScheduler: Broadcasting large task binary with size 1903.7 KiB\n",
      "25/05/22 12:55:36 WARN DAGScheduler: Broadcasting large task binary with size 1909.2 KiB\n",
      "25/05/22 12:55:37 WARN DAGScheduler: Broadcasting large task binary with size 1909.6 KiB\n",
      "25/05/22 12:55:37 WARN DAGScheduler: Broadcasting large task binary with size 1910.2 KiB\n",
      "25/05/22 12:55:38 WARN DAGScheduler: Broadcasting large task binary with size 1911.3 KiB\n",
      "25/05/22 12:55:38 WARN DAGScheduler: Broadcasting large task binary with size 1913.6 KiB\n",
      "25/05/22 12:55:38 WARN DAGScheduler: Broadcasting large task binary with size 1918.2 KiB\n",
      "25/05/22 12:55:38 WARN DAGScheduler: Broadcasting large task binary with size 1927.4 KiB\n",
      "25/05/22 12:55:39 WARN DAGScheduler: Broadcasting large task binary with size 1946.3 KiB\n",
      "25/05/22 12:55:39 WARN DAGScheduler: Broadcasting large task binary with size 1953.4 KiB\n",
      "25/05/22 12:55:41 WARN DAGScheduler: Broadcasting large task binary with size 1953.8 KiB\n",
      "25/05/22 12:55:41 WARN DAGScheduler: Broadcasting large task binary with size 1954.4 KiB\n",
      "25/05/22 12:55:41 WARN DAGScheduler: Broadcasting large task binary with size 1955.5 KiB\n",
      "25/05/22 12:55:42 WARN DAGScheduler: Broadcasting large task binary with size 1957.8 KiB\n",
      "25/05/22 12:55:42 WARN DAGScheduler: Broadcasting large task binary with size 1962.4 KiB\n",
      "25/05/22 12:55:42 WARN DAGScheduler: Broadcasting large task binary with size 1971.5 KiB\n",
      "25/05/22 12:55:42 WARN DAGScheduler: Broadcasting large task binary with size 1989.8 KiB\n",
      "25/05/22 12:55:43 WARN DAGScheduler: Broadcasting large task binary with size 1996.0 KiB\n",
      "25/05/22 12:55:44 WARN DAGScheduler: Broadcasting large task binary with size 1996.5 KiB\n",
      "25/05/22 12:55:45 WARN DAGScheduler: Broadcasting large task binary with size 1997.0 KiB\n",
      "25/05/22 12:55:45 WARN DAGScheduler: Broadcasting large task binary with size 1998.2 KiB\n",
      "25/05/22 12:55:45 WARN DAGScheduler: Broadcasting large task binary with size 2000.4 KiB\n",
      "25/05/22 12:55:45 WARN DAGScheduler: Broadcasting large task binary with size 2005.0 KiB\n",
      "25/05/22 12:55:46 WARN DAGScheduler: Broadcasting large task binary with size 2014.2 KiB\n",
      "25/05/22 12:55:46 WARN DAGScheduler: Broadcasting large task binary with size 2033.0 KiB\n",
      "25/05/22 12:55:47 WARN DAGScheduler: Broadcasting large task binary with size 2039.7 KiB\n",
      "25/05/22 12:55:48 WARN DAGScheduler: Broadcasting large task binary with size 2040.1 KiB\n",
      "25/05/22 12:55:49 WARN DAGScheduler: Broadcasting large task binary with size 2040.7 KiB\n",
      "25/05/22 12:55:49 WARN DAGScheduler: Broadcasting large task binary with size 2041.9 KiB\n",
      "25/05/22 12:55:49 WARN DAGScheduler: Broadcasting large task binary with size 2044.1 KiB\n",
      "25/05/22 12:55:49 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "25/05/22 12:55:50 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "25/05/22 12:55:50 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "25/05/22 12:55:51 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "25/05/22 12:55:52 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "25/05/22 12:55:52 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "25/05/22 12:55:52 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "25/05/22 12:55:53 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "25/05/22 12:55:53 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "25/05/22 12:55:53 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "25/05/22 12:55:54 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "25/05/22 12:55:54 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "25/05/22 12:55:56 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "25/05/22 12:55:56 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "25/05/22 12:55:56 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "25/05/22 12:55:56 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "25/05/22 12:55:57 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "25/05/22 12:55:57 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "25/05/22 12:55:57 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "25/05/22 12:55:58 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "25/05/22 12:55:59 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "25/05/22 12:56:00 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "25/05/22 12:56:00 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "25/05/22 12:56:00 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "25/05/22 12:56:00 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "25/05/22 12:56:01 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "25/05/22 12:56:01 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "25/05/22 12:56:02 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "25/05/22 12:56:03 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "25/05/22 12:56:03 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "25/05/22 12:56:04 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "25/05/22 12:56:04 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "25/05/22 12:56:04 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "25/05/22 12:56:04 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "25/05/22 12:56:05 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "25/05/22 12:56:05 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "25/05/22 12:56:07 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "25/05/22 12:56:07 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "25/05/22 12:56:07 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "25/05/22 12:56:07 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "25/05/22 12:56:08 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "25/05/22 12:56:08 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "25/05/22 12:56:09 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "25/05/22 12:56:09 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "25/05/22 12:56:10 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "25/05/22 12:56:11 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "25/05/22 12:56:11 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "25/05/22 12:56:11 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "25/05/22 12:56:12 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "25/05/22 12:56:12 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "25/05/22 12:56:12 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "[Stage 882:==============================================>        (17 + 3) / 20]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RMSE: 4.221, MAE: 2.615, R²: 0.837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Regression Models Training\n",
    "def train_regression_models(train_data, test_data):\n",
    "    print(\"REGRESSION MODELS TRAINING\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    evaluator = RegressionEvaluator(\n",
    "        labelCol=\"trip_duration_minutes\", \n",
    "        predictionCol=\"prediction\"\n",
    "    )\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    print(\"\\n1. Linear Regression\")\n",
    "    lr = LinearRegression(featuresCol=\"features\", labelCol=\"trip_duration_minutes\")\n",
    "    lr_model = lr.fit(train_data)\n",
    "    lr_predictions = lr_model.transform(test_data)\n",
    "    \n",
    "    lr_rmse = evaluator.evaluate(lr_predictions, {evaluator.metricName: \"rmse\"})\n",
    "    lr_mae = evaluator.evaluate(lr_predictions, {evaluator.metricName: \"mae\"})\n",
    "    lr_r2 = evaluator.evaluate(lr_predictions, {evaluator.metricName: \"r2\"})\n",
    "    \n",
    "    results['Linear_Regression'] = {\n",
    "        'RMSE': lr_rmse, 'MAE': lr_mae, 'R²': lr_r2, 'model': lr_model\n",
    "    }\n",
    "    \n",
    "    print(f\"   RMSE: {lr_rmse:.3f}, MAE: {lr_mae:.3f}, R²: {lr_r2:.3f}\")\n",
    "    \n",
    "    print(\"\\n2. Random Forest Regression\")\n",
    "    rf = RandomForestRegressor(\n",
    "        featuresCol=\"features\", \n",
    "        labelCol=\"trip_duration_minutes\",\n",
    "        numTrees=50, \n",
    "        maxDepth=10, \n",
    "        seed=42\n",
    "    )\n",
    "    rf_model = rf.fit(train_data)\n",
    "    rf_predictions = rf_model.transform(test_data)\n",
    "    \n",
    "    rf_rmse = evaluator.evaluate(rf_predictions, {evaluator.metricName: \"rmse\"})\n",
    "    rf_mae = evaluator.evaluate(rf_predictions, {evaluator.metricName: \"mae\"})\n",
    "    rf_r2 = evaluator.evaluate(rf_predictions, {evaluator.metricName: \"r2\"})\n",
    "    \n",
    "    results['Random_Forest'] = {\n",
    "        'RMSE': rf_rmse, 'MAE': rf_mae, 'R²': rf_r2, 'model': rf_model\n",
    "    }\n",
    "    \n",
    "    print(f\"   RMSE: {rf_rmse:.3f}, MAE: {rf_mae:.3f}, R²: {rf_r2:.3f}\")\n",
    "    \n",
    "    feature_importance = rf_model.featureImportances.toArray()\n",
    "    print(\"   Top 5 Feature Importances:\")\n",
    "    for i, importance in enumerate(feature_importance[:5]):\n",
    "        print(f\"     Feature {i}: {importance:.4f}\")\n",
    "    \n",
    "    print(\"\\n3. Gradient Boosted Trees\")\n",
    "    gbt = GBTRegressor(\n",
    "        featuresCol=\"features\", \n",
    "        labelCol=\"trip_duration_minutes\",\n",
    "        maxIter=50, \n",
    "        maxDepth=8, \n",
    "        seed=42\n",
    "    )\n",
    "    gbt_model = gbt.fit(train_data)\n",
    "    gbt_predictions = gbt_model.transform(test_data)\n",
    "    \n",
    "    gbt_rmse = evaluator.evaluate(gbt_predictions, {evaluator.metricName: \"rmse\"})\n",
    "    gbt_mae = evaluator.evaluate(gbt_predictions, {evaluator.metricName: \"mae\"})\n",
    "    gbt_r2 = evaluator.evaluate(gbt_predictions, {evaluator.metricName: \"r2\"})\n",
    "    \n",
    "    results['Gradient_Boosted_Trees'] = {\n",
    "        'RMSE': gbt_rmse, 'MAE': gbt_mae, 'R²': gbt_r2, 'model': gbt_model\n",
    "    }\n",
    "    \n",
    "    print(f\"   RMSE: {gbt_rmse:.3f}, MAE: {gbt_mae:.3f}, R²: {gbt_r2:.3f}\")\n",
    "    \n",
    "    return results, rf_predictions\n",
    "\n",
    "regression_results, best_predictions = train_regression_models(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14fc6d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CLASSIFICATION MODELS TRAINING\n",
      "==================================================\n",
      "\n",
      "1. Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Accuracy: 0.896, Precision: 0.892, Recall: 0.896\n",
      "   F1: 0.890, AUC: 0.940\n",
      "\n",
      "2. Random Forest Classification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/22 13:00:51 WARN MemoryStore: Not enough space to cache rdd_2146_12 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:00:51 WARN BlockManager: Persisting block rdd_2146_12 to disk instead.\n",
      "25/05/22 13:00:51 WARN MemoryStore: Not enough space to cache rdd_2146_19 in memory! (computed 43.1 MiB so far)\n",
      "25/05/22 13:00:51 WARN BlockManager: Persisting block rdd_2146_19 to disk instead.\n",
      "25/05/22 13:00:51 WARN MemoryStore: Not enough space to cache rdd_2146_17 in memory! (computed 43.1 MiB so far)\n",
      "25/05/22 13:00:51 WARN BlockManager: Persisting block rdd_2146_17 to disk instead.\n",
      "25/05/22 13:00:51 WARN MemoryStore: Not enough space to cache rdd_2146_2 in memory! (computed 28.7 MiB so far)\n",
      "25/05/22 13:00:51 WARN BlockManager: Persisting block rdd_2146_2 to disk instead.\n",
      "25/05/22 13:00:51 WARN MemoryStore: Not enough space to cache rdd_2146_14 in memory! (computed 43.1 MiB so far)\n",
      "25/05/22 13:00:51 WARN BlockManager: Persisting block rdd_2146_14 to disk instead.\n",
      "25/05/22 13:00:51 WARN MemoryStore: Not enough space to cache rdd_2146_4 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:00:51 WARN BlockManager: Persisting block rdd_2146_4 to disk instead.\n",
      "25/05/22 13:00:51 WARN MemoryStore: Not enough space to cache rdd_2146_0 in memory! (computed 19.1 MiB so far)\n",
      "25/05/22 13:00:51 WARN BlockManager: Persisting block rdd_2146_0 to disk instead.\n",
      "25/05/22 13:00:51 WARN MemoryStore: Not enough space to cache rdd_2146_1 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:00:51 WARN MemoryStore: Not enough space to cache rdd_2146_16 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:00:51 WARN BlockManager: Persisting block rdd_2146_1 to disk instead.\n",
      "25/05/22 13:00:51 WARN MemoryStore: Not enough space to cache rdd_2146_6 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:00:51 WARN BlockManager: Persisting block rdd_2146_6 to disk instead.\n",
      "25/05/22 13:00:51 WARN BlockManager: Persisting block rdd_2146_16 to disk instead.\n",
      "25/05/22 13:00:51 WARN MemoryStore: Not enough space to cache rdd_2146_8 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:00:51 WARN BlockManager: Persisting block rdd_2146_8 to disk instead.\n",
      "25/05/22 13:00:51 WARN MemoryStore: Not enough space to cache rdd_2146_10 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:00:51 WARN BlockManager: Persisting block rdd_2146_10 to disk instead.\n",
      "25/05/22 13:00:51 WARN MemoryStore: Not enough space to cache rdd_2146_5 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:00:51 WARN BlockManager: Persisting block rdd_2146_5 to disk instead.\n",
      "25/05/22 13:00:51 WARN MemoryStore: Not enough space to cache rdd_2146_7 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:00:51 WARN BlockManager: Persisting block rdd_2146_7 to disk instead.\n",
      "25/05/22 13:00:51 WARN MemoryStore: Not enough space to cache rdd_2146_18 in memory! (computed 43.1 MiB so far)\n",
      "25/05/22 13:00:51 WARN BlockManager: Persisting block rdd_2146_18 to disk instead.\n",
      "25/05/22 13:00:51 WARN MemoryStore: Not enough space to cache rdd_2146_11 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:00:51 WARN BlockManager: Persisting block rdd_2146_11 to disk instead.\n",
      "25/05/22 13:00:56 WARN MemoryStore: Not enough space to cache rdd_2146_10 in memory! (computed 101.0 MiB so far)\n",
      "25/05/22 13:00:56 WARN MemoryStore: Not enough space to cache rdd_2146_14 in memory! (computed 43.1 MiB so far)\n",
      "25/05/22 13:00:56 WARN MemoryStore: Not enough space to cache rdd_2146_2 in memory! (computed 19.1 MiB so far)\n",
      "25/05/22 13:00:56 WARN MemoryStore: Not enough space to cache rdd_2146_18 in memory! (computed 43.1 MiB so far)\n",
      "25/05/22 13:00:56 WARN MemoryStore: Not enough space to cache rdd_2146_16 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:00:56 WARN MemoryStore: Not enough space to cache rdd_2146_17 in memory! (computed 43.1 MiB so far)\n",
      "25/05/22 13:00:56 WARN MemoryStore: Not enough space to cache rdd_2146_8 in memory! (computed 101.0 MiB so far)\n",
      "25/05/22 13:00:56 WARN MemoryStore: Not enough space to cache rdd_2146_5 in memory! (computed 101.0 MiB so far)\n",
      "25/05/22 13:00:59 WARN MemoryStore: Not enough space to cache rdd_2146_2 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:00:59 WARN MemoryStore: Not enough space to cache rdd_2146_16 in memory! (computed 43.1 MiB so far)\n",
      "25/05/22 13:00:59 WARN MemoryStore: Not enough space to cache rdd_2146_17 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:00:59 WARN MemoryStore: Not enough space to cache rdd_2146_8 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:00:59 WARN MemoryStore: Not enough space to cache rdd_2146_5 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:00:59 WARN MemoryStore: Not enough space to cache rdd_2146_10 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:00:59 WARN MemoryStore: Not enough space to cache rdd_2146_18 in memory! (computed 101.0 MiB so far)\n",
      "25/05/22 13:01:00 WARN MemoryStore: Not enough space to cache rdd_2146_14 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:01:04 WARN MemoryStore: Not enough space to cache rdd_2146_2 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:01:04 WARN MemoryStore: Not enough space to cache rdd_2146_10 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:01:04 WARN MemoryStore: Not enough space to cache rdd_2146_16 in memory! (computed 43.1 MiB so far)\n",
      "25/05/22 13:01:04 WARN MemoryStore: Not enough space to cache rdd_2146_18 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:01:04 WARN MemoryStore: Not enough space to cache rdd_2146_5 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:01:04 WARN MemoryStore: Not enough space to cache rdd_2146_8 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:01:04 WARN MemoryStore: Not enough space to cache rdd_2146_14 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:01:04 WARN MemoryStore: Not enough space to cache rdd_2146_17 in memory! (computed 101.0 MiB so far)\n",
      "25/05/22 13:01:10 WARN MemoryStore: Not enough space to cache rdd_2146_18 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:01:10 WARN MemoryStore: Not enough space to cache rdd_2146_16 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:01:10 WARN MemoryStore: Not enough space to cache rdd_2146_8 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:01:10 WARN MemoryStore: Not enough space to cache rdd_2146_17 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:01:10 WARN MemoryStore: Not enough space to cache rdd_2146_10 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:01:10 WARN MemoryStore: Not enough space to cache rdd_2146_2 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:01:10 WARN MemoryStore: Not enough space to cache rdd_2146_5 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:01:10 WARN MemoryStore: Not enough space to cache rdd_2146_14 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:01:16 WARN MemoryStore: Not enough space to cache rdd_2146_17 in memory! (computed 43.1 MiB so far)\n",
      "25/05/22 13:01:16 WARN MemoryStore: Not enough space to cache rdd_2146_14 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:01:16 WARN MemoryStore: Not enough space to cache rdd_2146_5 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:01:16 WARN MemoryStore: Not enough space to cache rdd_2146_2 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:01:16 WARN MemoryStore: Not enough space to cache rdd_2146_10 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:01:16 WARN MemoryStore: Not enough space to cache rdd_2146_16 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:01:16 WARN MemoryStore: Not enough space to cache rdd_2146_18 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:01:16 WARN MemoryStore: Not enough space to cache rdd_2146_8 in memory! (computed 101.0 MiB so far)\n",
      "25/05/22 13:01:25 WARN MemoryStore: Not enough space to cache rdd_2146_16 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:01:25 WARN MemoryStore: Not enough space to cache rdd_2146_14 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:01:25 WARN MemoryStore: Not enough space to cache rdd_2146_8 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:01:25 WARN MemoryStore: Not enough space to cache rdd_2146_10 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:01:25 WARN MemoryStore: Not enough space to cache rdd_2146_5 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:01:25 WARN MemoryStore: Not enough space to cache rdd_2146_18 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:01:25 WARN MemoryStore: Not enough space to cache rdd_2146_2 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:01:25 WARN MemoryStore: Not enough space to cache rdd_2146_17 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:01:34 WARN DAGScheduler: Broadcasting large task binary with size 1074.0 KiB\n",
      "25/05/22 13:01:35 WARN MemoryStore: Not enough space to cache rdd_2146_2 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:01:35 WARN MemoryStore: Not enough space to cache rdd_2146_17 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:01:35 WARN MemoryStore: Not enough space to cache rdd_2146_5 in memory! (computed 43.1 MiB so far)\n",
      "25/05/22 13:01:35 WARN MemoryStore: Not enough space to cache rdd_2146_8 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:01:35 WARN MemoryStore: Not enough space to cache rdd_2146_18 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:01:35 WARN MemoryStore: Not enough space to cache rdd_2146_14 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:01:35 WARN MemoryStore: Not enough space to cache rdd_2146_16 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:01:35 WARN MemoryStore: Not enough space to cache rdd_2146_10 in memory! (computed 101.0 MiB so far)\n",
      "25/05/22 13:01:47 WARN DAGScheduler: Broadcasting large task binary with size 1998.3 KiB\n",
      "25/05/22 13:01:47 WARN MemoryStore: Not enough space to cache rdd_2146_14 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:01:47 WARN MemoryStore: Not enough space to cache rdd_2146_5 in memory! (computed 43.1 MiB so far)\n",
      "25/05/22 13:01:47 WARN MemoryStore: Not enough space to cache rdd_2146_18 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:01:47 WARN MemoryStore: Not enough space to cache rdd_2146_8 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:01:47 WARN MemoryStore: Not enough space to cache rdd_2146_2 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:01:47 WARN MemoryStore: Not enough space to cache rdd_2146_17 in memory! (computed 101.0 MiB so far)\n",
      "25/05/22 13:01:47 WARN MemoryStore: Not enough space to cache rdd_2146_10 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:01:48 WARN MemoryStore: Not enough space to cache rdd_2146_16 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:02:04 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n",
      "25/05/22 13:02:04 WARN MemoryStore: Not enough space to cache rdd_2146_2 in memory! (computed 43.1 MiB so far)\n",
      "25/05/22 13:02:04 WARN MemoryStore: Not enough space to cache rdd_2146_16 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:02:04 WARN MemoryStore: Not enough space to cache rdd_2146_10 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:02:04 WARN MemoryStore: Not enough space to cache rdd_2146_14 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:02:04 WARN MemoryStore: Not enough space to cache rdd_2146_5 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:02:04 WARN MemoryStore: Not enough space to cache rdd_2146_8 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:02:05 WARN MemoryStore: Not enough space to cache rdd_2146_17 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:02:05 WARN MemoryStore: Not enough space to cache rdd_2146_18 in memory! (computed 101.0 MiB so far)\n",
      "25/05/22 13:02:27 WARN DAGScheduler: Broadcasting large task binary with size 1080.8 KiB\n",
      "25/05/22 13:02:27 WARN DAGScheduler: Broadcasting large task binary with size 6.9 MiB\n",
      "25/05/22 13:02:28 WARN MemoryStore: Not enough space to cache rdd_2146_5 in memory! (computed 28.7 MiB so far)\n",
      "25/05/22 13:02:28 WARN MemoryStore: Not enough space to cache rdd_2146_8 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:02:29 WARN MemoryStore: Not enough space to cache rdd_2146_10 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:02:29 WARN MemoryStore: Not enough space to cache rdd_2146_14 in memory! (computed 43.1 MiB so far)\n",
      "25/05/22 13:02:29 WARN MemoryStore: Not enough space to cache rdd_2146_16 in memory! (computed 101.0 MiB so far)\n",
      "25/05/22 13:02:29 WARN MemoryStore: Not enough space to cache rdd_2146_17 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:02:29 WARN MemoryStore: Not enough space to cache rdd_2146_2 in memory! (computed 64.9 MiB so far)\n",
      "25/05/22 13:02:29 WARN MemoryStore: Not enough space to cache rdd_2146_18 in memory! (computed 101.0 MiB so far)\n",
      "25/05/22 13:02:58 WARN DAGScheduler: Broadcasting large task binary with size 2040.9 KiB\n",
      "25/05/22 13:02:59 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "25/05/22 13:03:22 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "25/05/22 13:03:43 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "25/05/22 13:04:04 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "25/05/22 13:04:25 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Accuracy: 0.912, Precision: 0.909, Recall: 0.912\n",
      "   F1: 0.910, AUC: 0.950\n",
      "\n",
      "3. Gradient Boosted Trees Classification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/22 13:06:52 WARN DAGScheduler: Broadcasting large task binary with size 1001.0 KiB\n",
      "25/05/22 13:06:53 WARN DAGScheduler: Broadcasting large task binary with size 1003.3 KiB\n",
      "25/05/22 13:06:53 WARN DAGScheduler: Broadcasting large task binary with size 1007.8 KiB\n",
      "25/05/22 13:06:53 WARN DAGScheduler: Broadcasting large task binary with size 1016.9 KiB\n",
      "25/05/22 13:06:54 WARN DAGScheduler: Broadcasting large task binary with size 1035.7 KiB\n",
      "25/05/22 13:06:54 WARN DAGScheduler: Broadcasting large task binary with size 1042.5 KiB\n",
      "25/05/22 13:06:56 WARN DAGScheduler: Broadcasting large task binary with size 1042.9 KiB\n",
      "25/05/22 13:06:56 WARN DAGScheduler: Broadcasting large task binary with size 1043.5 KiB\n",
      "25/05/22 13:06:56 WARN DAGScheduler: Broadcasting large task binary with size 1044.7 KiB\n",
      "25/05/22 13:06:57 WARN DAGScheduler: Broadcasting large task binary with size 1047.0 KiB\n",
      "25/05/22 13:06:57 WARN DAGScheduler: Broadcasting large task binary with size 1051.5 KiB\n",
      "25/05/22 13:06:57 WARN DAGScheduler: Broadcasting large task binary with size 1060.6 KiB\n",
      "25/05/22 13:06:58 WARN DAGScheduler: Broadcasting large task binary with size 1079.4 KiB\n",
      "25/05/22 13:06:58 WARN DAGScheduler: Broadcasting large task binary with size 1086.0 KiB\n",
      "25/05/22 13:06:59 WARN DAGScheduler: Broadcasting large task binary with size 1086.5 KiB\n",
      "25/05/22 13:07:00 WARN DAGScheduler: Broadcasting large task binary with size 1087.1 KiB\n",
      "25/05/22 13:07:00 WARN DAGScheduler: Broadcasting large task binary with size 1088.2 KiB\n",
      "25/05/22 13:07:00 WARN DAGScheduler: Broadcasting large task binary with size 1090.5 KiB\n",
      "25/05/22 13:07:00 WARN DAGScheduler: Broadcasting large task binary with size 1095.1 KiB\n",
      "25/05/22 13:07:01 WARN DAGScheduler: Broadcasting large task binary with size 1104.2 KiB\n",
      "25/05/22 13:07:01 WARN DAGScheduler: Broadcasting large task binary with size 1122.9 KiB\n",
      "25/05/22 13:07:02 WARN DAGScheduler: Broadcasting large task binary with size 1129.7 KiB\n",
      "25/05/22 13:07:03 WARN DAGScheduler: Broadcasting large task binary with size 1130.1 KiB\n",
      "25/05/22 13:07:03 WARN DAGScheduler: Broadcasting large task binary with size 1130.7 KiB\n",
      "25/05/22 13:07:04 WARN DAGScheduler: Broadcasting large task binary with size 1131.8 KiB\n",
      "25/05/22 13:07:04 WARN DAGScheduler: Broadcasting large task binary with size 1134.1 KiB\n",
      "25/05/22 13:07:04 WARN DAGScheduler: Broadcasting large task binary with size 1138.7 KiB\n",
      "25/05/22 13:07:04 WARN DAGScheduler: Broadcasting large task binary with size 1147.8 KiB\n",
      "25/05/22 13:07:05 WARN DAGScheduler: Broadcasting large task binary with size 1166.5 KiB\n",
      "25/05/22 13:07:05 WARN DAGScheduler: Broadcasting large task binary with size 1173.1 KiB\n",
      "25/05/22 13:07:06 WARN DAGScheduler: Broadcasting large task binary with size 1173.5 KiB\n",
      "25/05/22 13:07:07 WARN DAGScheduler: Broadcasting large task binary with size 1174.1 KiB\n",
      "25/05/22 13:07:07 WARN DAGScheduler: Broadcasting large task binary with size 1175.2 KiB\n",
      "25/05/22 13:07:07 WARN DAGScheduler: Broadcasting large task binary with size 1177.5 KiB\n",
      "25/05/22 13:07:08 WARN DAGScheduler: Broadcasting large task binary with size 1182.0 KiB\n",
      "25/05/22 13:07:08 WARN DAGScheduler: Broadcasting large task binary with size 1191.1 KiB\n",
      "25/05/22 13:07:08 WARN DAGScheduler: Broadcasting large task binary with size 1209.9 KiB\n",
      "25/05/22 13:07:09 WARN DAGScheduler: Broadcasting large task binary with size 1216.8 KiB\n",
      "25/05/22 13:07:10 WARN DAGScheduler: Broadcasting large task binary with size 1217.2 KiB\n",
      "25/05/22 13:07:10 WARN DAGScheduler: Broadcasting large task binary with size 1217.8 KiB\n",
      "25/05/22 13:07:10 WARN DAGScheduler: Broadcasting large task binary with size 1219.0 KiB\n",
      "25/05/22 13:07:11 WARN DAGScheduler: Broadcasting large task binary with size 1221.3 KiB\n",
      "25/05/22 13:07:11 WARN DAGScheduler: Broadcasting large task binary with size 1225.8 KiB\n",
      "25/05/22 13:07:11 WARN DAGScheduler: Broadcasting large task binary with size 1234.9 KiB\n",
      "25/05/22 13:07:12 WARN DAGScheduler: Broadcasting large task binary with size 1253.7 KiB\n",
      "25/05/22 13:07:12 WARN DAGScheduler: Broadcasting large task binary with size 1260.1 KiB\n",
      "25/05/22 13:07:13 WARN DAGScheduler: Broadcasting large task binary with size 1260.5 KiB\n",
      "25/05/22 13:07:14 WARN DAGScheduler: Broadcasting large task binary with size 1261.1 KiB\n",
      "25/05/22 13:07:14 WARN DAGScheduler: Broadcasting large task binary with size 1262.3 KiB\n",
      "25/05/22 13:07:14 WARN DAGScheduler: Broadcasting large task binary with size 1264.6 KiB\n",
      "25/05/22 13:07:14 WARN DAGScheduler: Broadcasting large task binary with size 1269.1 KiB\n",
      "25/05/22 13:07:15 WARN DAGScheduler: Broadcasting large task binary with size 1278.3 KiB\n",
      "25/05/22 13:07:15 WARN DAGScheduler: Broadcasting large task binary with size 1297.0 KiB\n",
      "25/05/22 13:07:16 WARN DAGScheduler: Broadcasting large task binary with size 1303.7 KiB\n",
      "25/05/22 13:07:17 WARN DAGScheduler: Broadcasting large task binary with size 1304.1 KiB\n",
      "25/05/22 13:07:17 WARN DAGScheduler: Broadcasting large task binary with size 1304.7 KiB\n",
      "25/05/22 13:07:17 WARN DAGScheduler: Broadcasting large task binary with size 1305.8 KiB\n",
      "25/05/22 13:07:18 WARN DAGScheduler: Broadcasting large task binary with size 1308.1 KiB\n",
      "25/05/22 13:07:18 WARN DAGScheduler: Broadcasting large task binary with size 1312.6 KiB\n",
      "25/05/22 13:07:18 WARN DAGScheduler: Broadcasting large task binary with size 1321.8 KiB\n",
      "25/05/22 13:07:19 WARN DAGScheduler: Broadcasting large task binary with size 1340.5 KiB\n",
      "25/05/22 13:07:19 WARN DAGScheduler: Broadcasting large task binary with size 1347.1 KiB\n",
      "25/05/22 13:07:21 WARN DAGScheduler: Broadcasting large task binary with size 1347.6 KiB\n",
      "25/05/22 13:07:21 WARN DAGScheduler: Broadcasting large task binary with size 1348.1 KiB\n",
      "25/05/22 13:07:21 WARN DAGScheduler: Broadcasting large task binary with size 1349.3 KiB\n",
      "25/05/22 13:07:21 WARN DAGScheduler: Broadcasting large task binary with size 1351.6 KiB\n",
      "25/05/22 13:07:22 WARN DAGScheduler: Broadcasting large task binary with size 1356.1 KiB\n",
      "25/05/22 13:07:22 WARN DAGScheduler: Broadcasting large task binary with size 1365.2 KiB\n",
      "25/05/22 13:07:22 WARN DAGScheduler: Broadcasting large task binary with size 1384.0 KiB\n",
      "25/05/22 13:07:23 WARN DAGScheduler: Broadcasting large task binary with size 1390.7 KiB\n",
      "25/05/22 13:07:24 WARN DAGScheduler: Broadcasting large task binary with size 1391.2 KiB\n",
      "25/05/22 13:07:25 WARN DAGScheduler: Broadcasting large task binary with size 1391.8 KiB\n",
      "25/05/22 13:07:25 WARN DAGScheduler: Broadcasting large task binary with size 1392.9 KiB\n",
      "25/05/22 13:07:25 WARN DAGScheduler: Broadcasting large task binary with size 1395.3 KiB\n",
      "25/05/22 13:07:25 WARN DAGScheduler: Broadcasting large task binary with size 1399.8 KiB\n",
      "25/05/22 13:07:26 WARN DAGScheduler: Broadcasting large task binary with size 1408.9 KiB\n",
      "25/05/22 13:07:26 WARN DAGScheduler: Broadcasting large task binary with size 1427.7 KiB\n",
      "25/05/22 13:07:27 WARN DAGScheduler: Broadcasting large task binary with size 1434.6 KiB\n",
      "25/05/22 13:07:28 WARN DAGScheduler: Broadcasting large task binary with size 1435.0 KiB\n",
      "25/05/22 13:07:28 WARN DAGScheduler: Broadcasting large task binary with size 1435.6 KiB\n",
      "25/05/22 13:07:28 WARN DAGScheduler: Broadcasting large task binary with size 1436.7 KiB\n",
      "25/05/22 13:07:29 WARN DAGScheduler: Broadcasting large task binary with size 1439.0 KiB\n",
      "25/05/22 13:07:29 WARN DAGScheduler: Broadcasting large task binary with size 1443.6 KiB\n",
      "25/05/22 13:07:29 WARN DAGScheduler: Broadcasting large task binary with size 1452.7 KiB\n",
      "25/05/22 13:07:30 WARN DAGScheduler: Broadcasting large task binary with size 1471.6 KiB\n",
      "25/05/22 13:07:31 WARN DAGScheduler: Broadcasting large task binary with size 1478.5 KiB\n",
      "25/05/22 13:07:32 WARN DAGScheduler: Broadcasting large task binary with size 1479.0 KiB\n",
      "25/05/22 13:07:32 WARN DAGScheduler: Broadcasting large task binary with size 1479.5 KiB\n",
      "25/05/22 13:07:32 WARN DAGScheduler: Broadcasting large task binary with size 1480.7 KiB\n",
      "25/05/22 13:07:32 WARN DAGScheduler: Broadcasting large task binary with size 1483.0 KiB\n",
      "25/05/22 13:07:33 WARN DAGScheduler: Broadcasting large task binary with size 1487.5 KiB\n",
      "25/05/22 13:07:33 WARN DAGScheduler: Broadcasting large task binary with size 1496.6 KiB\n",
      "25/05/22 13:07:33 WARN DAGScheduler: Broadcasting large task binary with size 1515.4 KiB\n",
      "25/05/22 13:07:34 WARN DAGScheduler: Broadcasting large task binary with size 1522.1 KiB\n",
      "25/05/22 13:07:35 WARN DAGScheduler: Broadcasting large task binary with size 1522.6 KiB\n",
      "25/05/22 13:07:35 WARN DAGScheduler: Broadcasting large task binary with size 1523.2 KiB\n",
      "25/05/22 13:07:36 WARN DAGScheduler: Broadcasting large task binary with size 1524.3 KiB\n",
      "25/05/22 13:07:36 WARN DAGScheduler: Broadcasting large task binary with size 1526.6 KiB\n",
      "25/05/22 13:07:37 WARN DAGScheduler: Broadcasting large task binary with size 1531.2 KiB\n",
      "25/05/22 13:07:37 WARN DAGScheduler: Broadcasting large task binary with size 1540.3 KiB\n",
      "25/05/22 13:07:37 WARN DAGScheduler: Broadcasting large task binary with size 1559.1 KiB\n",
      "25/05/22 13:07:38 WARN DAGScheduler: Broadcasting large task binary with size 1565.9 KiB\n",
      "25/05/22 13:07:39 WARN DAGScheduler: Broadcasting large task binary with size 1566.4 KiB\n",
      "25/05/22 13:07:39 WARN DAGScheduler: Broadcasting large task binary with size 1567.0 KiB\n",
      "25/05/22 13:07:40 WARN DAGScheduler: Broadcasting large task binary with size 1568.1 KiB\n",
      "25/05/22 13:07:40 WARN DAGScheduler: Broadcasting large task binary with size 1570.4 KiB\n",
      "25/05/22 13:07:40 WARN DAGScheduler: Broadcasting large task binary with size 1574.9 KiB\n",
      "25/05/22 13:07:41 WARN DAGScheduler: Broadcasting large task binary with size 1584.0 KiB\n",
      "25/05/22 13:07:41 WARN DAGScheduler: Broadcasting large task binary with size 1602.8 KiB\n",
      "25/05/22 13:07:42 WARN DAGScheduler: Broadcasting large task binary with size 1609.6 KiB\n",
      "25/05/22 13:07:43 WARN DAGScheduler: Broadcasting large task binary with size 1610.1 KiB\n",
      "25/05/22 13:07:43 WARN DAGScheduler: Broadcasting large task binary with size 1610.6 KiB\n",
      "25/05/22 13:07:43 WARN DAGScheduler: Broadcasting large task binary with size 1611.8 KiB\n",
      "25/05/22 13:07:44 WARN DAGScheduler: Broadcasting large task binary with size 1614.1 KiB\n",
      "25/05/22 13:07:44 WARN DAGScheduler: Broadcasting large task binary with size 1618.6 KiB\n",
      "25/05/22 13:07:44 WARN DAGScheduler: Broadcasting large task binary with size 1627.7 KiB\n",
      "25/05/22 13:07:45 WARN DAGScheduler: Broadcasting large task binary with size 1646.4 KiB\n",
      "25/05/22 13:07:45 WARN DAGScheduler: Broadcasting large task binary with size 1653.3 KiB\n",
      "25/05/22 13:07:46 WARN DAGScheduler: Broadcasting large task binary with size 1653.7 KiB\n",
      "25/05/22 13:07:47 WARN DAGScheduler: Broadcasting large task binary with size 1654.3 KiB\n",
      "25/05/22 13:07:47 WARN DAGScheduler: Broadcasting large task binary with size 1655.4 KiB\n",
      "25/05/22 13:07:47 WARN DAGScheduler: Broadcasting large task binary with size 1657.7 KiB\n",
      "25/05/22 13:07:48 WARN DAGScheduler: Broadcasting large task binary with size 1662.3 KiB\n",
      "25/05/22 13:07:48 WARN DAGScheduler: Broadcasting large task binary with size 1671.4 KiB\n",
      "25/05/22 13:07:48 WARN DAGScheduler: Broadcasting large task binary with size 1690.3 KiB\n",
      "25/05/22 13:07:49 WARN DAGScheduler: Broadcasting large task binary with size 1697.1 KiB\n",
      "25/05/22 13:07:51 WARN DAGScheduler: Broadcasting large task binary with size 1697.6 KiB\n",
      "25/05/22 13:07:51 WARN DAGScheduler: Broadcasting large task binary with size 1698.1 KiB\n",
      "25/05/22 13:07:51 WARN DAGScheduler: Broadcasting large task binary with size 1699.3 KiB\n",
      "25/05/22 13:07:51 WARN DAGScheduler: Broadcasting large task binary with size 1701.6 KiB\n",
      "25/05/22 13:07:52 WARN DAGScheduler: Broadcasting large task binary with size 1706.1 KiB\n",
      "25/05/22 13:07:52 WARN DAGScheduler: Broadcasting large task binary with size 1715.2 KiB\n",
      "25/05/22 13:07:52 WARN DAGScheduler: Broadcasting large task binary with size 1733.9 KiB\n",
      "25/05/22 13:07:53 WARN DAGScheduler: Broadcasting large task binary with size 1740.8 KiB\n",
      "25/05/22 13:07:54 WARN DAGScheduler: Broadcasting large task binary with size 1741.3 KiB\n",
      "25/05/22 13:07:54 WARN DAGScheduler: Broadcasting large task binary with size 1741.8 KiB\n",
      "25/05/22 13:07:55 WARN DAGScheduler: Broadcasting large task binary with size 1743.0 KiB\n",
      "25/05/22 13:07:55 WARN DAGScheduler: Broadcasting large task binary with size 1745.3 KiB\n",
      "25/05/22 13:07:55 WARN DAGScheduler: Broadcasting large task binary with size 1749.8 KiB\n",
      "25/05/22 13:07:56 WARN DAGScheduler: Broadcasting large task binary with size 1758.9 KiB\n",
      "25/05/22 13:07:56 WARN DAGScheduler: Broadcasting large task binary with size 1777.7 KiB\n",
      "25/05/22 13:07:56 WARN DAGScheduler: Broadcasting large task binary with size 1784.2 KiB\n",
      "25/05/22 13:07:58 WARN DAGScheduler: Broadcasting large task binary with size 1784.7 KiB\n",
      "25/05/22 13:07:58 WARN DAGScheduler: Broadcasting large task binary with size 1785.3 KiB\n",
      "25/05/22 13:07:58 WARN DAGScheduler: Broadcasting large task binary with size 1786.4 KiB\n",
      "25/05/22 13:07:59 WARN DAGScheduler: Broadcasting large task binary with size 1788.8 KiB\n",
      "25/05/22 13:07:59 WARN DAGScheduler: Broadcasting large task binary with size 1793.3 KiB\n",
      "25/05/22 13:07:59 WARN DAGScheduler: Broadcasting large task binary with size 1802.4 KiB\n",
      "25/05/22 13:08:00 WARN DAGScheduler: Broadcasting large task binary with size 1821.2 KiB\n",
      "25/05/22 13:08:00 WARN DAGScheduler: Broadcasting large task binary with size 1828.0 KiB\n",
      "25/05/22 13:08:01 WARN DAGScheduler: Broadcasting large task binary with size 1828.5 KiB\n",
      "25/05/22 13:08:02 WARN DAGScheduler: Broadcasting large task binary with size 1829.1 KiB\n",
      "25/05/22 13:08:02 WARN DAGScheduler: Broadcasting large task binary with size 1830.3 KiB\n",
      "25/05/22 13:08:02 WARN DAGScheduler: Broadcasting large task binary with size 1832.6 KiB\n",
      "25/05/22 13:08:03 WARN DAGScheduler: Broadcasting large task binary with size 1837.2 KiB\n",
      "25/05/22 13:08:03 WARN DAGScheduler: Broadcasting large task binary with size 1846.3 KiB\n",
      "25/05/22 13:08:03 WARN DAGScheduler: Broadcasting large task binary with size 1865.0 KiB\n",
      "25/05/22 13:08:04 WARN DAGScheduler: Broadcasting large task binary with size 1871.7 KiB\n",
      "25/05/22 13:08:05 WARN DAGScheduler: Broadcasting large task binary with size 1872.2 KiB\n",
      "25/05/22 13:08:06 WARN DAGScheduler: Broadcasting large task binary with size 1872.8 KiB\n",
      "25/05/22 13:08:06 WARN DAGScheduler: Broadcasting large task binary with size 1873.9 KiB\n",
      "25/05/22 13:08:06 WARN DAGScheduler: Broadcasting large task binary with size 1876.2 KiB\n",
      "25/05/22 13:08:06 WARN DAGScheduler: Broadcasting large task binary with size 1880.7 KiB\n",
      "25/05/22 13:08:07 WARN DAGScheduler: Broadcasting large task binary with size 1889.8 KiB\n",
      "25/05/22 13:08:07 WARN DAGScheduler: Broadcasting large task binary with size 1908.5 KiB\n",
      "25/05/22 13:08:08 WARN DAGScheduler: Broadcasting large task binary with size 1915.1 KiB\n",
      "25/05/22 13:08:09 WARN DAGScheduler: Broadcasting large task binary with size 1915.6 KiB\n",
      "25/05/22 13:08:09 WARN DAGScheduler: Broadcasting large task binary with size 1916.1 KiB\n",
      "25/05/22 13:08:10 WARN DAGScheduler: Broadcasting large task binary with size 1917.3 KiB\n",
      "25/05/22 13:08:10 WARN DAGScheduler: Broadcasting large task binary with size 1919.6 KiB\n",
      "25/05/22 13:08:10 WARN DAGScheduler: Broadcasting large task binary with size 1924.1 KiB\n",
      "25/05/22 13:08:11 WARN DAGScheduler: Broadcasting large task binary with size 1933.3 KiB\n",
      "25/05/22 13:08:11 WARN DAGScheduler: Broadcasting large task binary with size 1952.0 KiB\n",
      "25/05/22 13:08:12 WARN DAGScheduler: Broadcasting large task binary with size 1958.7 KiB\n",
      "25/05/22 13:08:13 WARN DAGScheduler: Broadcasting large task binary with size 1959.2 KiB\n",
      "25/05/22 13:08:13 WARN DAGScheduler: Broadcasting large task binary with size 1959.8 KiB\n",
      "25/05/22 13:08:13 WARN DAGScheduler: Broadcasting large task binary with size 1960.9 KiB\n",
      "25/05/22 13:08:14 WARN DAGScheduler: Broadcasting large task binary with size 1963.2 KiB\n",
      "25/05/22 13:08:14 WARN DAGScheduler: Broadcasting large task binary with size 1967.8 KiB\n",
      "25/05/22 13:08:14 WARN DAGScheduler: Broadcasting large task binary with size 1976.9 KiB\n",
      "25/05/22 13:08:15 WARN DAGScheduler: Broadcasting large task binary with size 1995.7 KiB\n",
      "25/05/22 13:08:15 WARN DAGScheduler: Broadcasting large task binary with size 2002.4 KiB\n",
      "25/05/22 13:08:16 WARN DAGScheduler: Broadcasting large task binary with size 2002.9 KiB\n",
      "25/05/22 13:08:17 WARN DAGScheduler: Broadcasting large task binary with size 2003.5 KiB\n",
      "25/05/22 13:08:17 WARN DAGScheduler: Broadcasting large task binary with size 2004.6 KiB\n",
      "25/05/22 13:08:17 WARN DAGScheduler: Broadcasting large task binary with size 2006.9 KiB\n",
      "25/05/22 13:08:17 WARN DAGScheduler: Broadcasting large task binary with size 2011.4 KiB\n",
      "25/05/22 13:08:18 WARN DAGScheduler: Broadcasting large task binary with size 2020.5 KiB\n",
      "25/05/22 13:08:18 WARN DAGScheduler: Broadcasting large task binary with size 2039.2 KiB\n",
      "25/05/22 13:08:19 WARN DAGScheduler: Broadcasting large task binary with size 2046.0 KiB\n",
      "25/05/22 13:08:20 WARN DAGScheduler: Broadcasting large task binary with size 2046.5 KiB\n",
      "25/05/22 13:08:20 WARN DAGScheduler: Broadcasting large task binary with size 2047.1 KiB\n",
      "25/05/22 13:08:21 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "25/05/22 13:08:21 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "25/05/22 13:08:21 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "25/05/22 13:08:22 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "25/05/22 13:08:22 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "25/05/22 13:08:22 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "25/05/22 13:08:24 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "25/05/22 13:08:24 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "25/05/22 13:08:24 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "25/05/22 13:08:25 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "25/05/22 13:08:25 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "25/05/22 13:08:25 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "25/05/22 13:08:26 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "25/05/22 13:08:26 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "25/05/22 13:08:28 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "25/05/22 13:08:28 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "25/05/22 13:08:28 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "25/05/22 13:08:28 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "25/05/22 13:08:29 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "25/05/22 13:08:29 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "25/05/22 13:08:29 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "25/05/22 13:08:30 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "25/05/22 13:08:31 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "25/05/22 13:08:32 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "25/05/22 13:08:32 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "25/05/22 13:08:32 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "25/05/22 13:08:32 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "25/05/22 13:08:33 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "25/05/22 13:08:33 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "25/05/22 13:08:34 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "25/05/22 13:08:35 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "25/05/22 13:08:36 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "25/05/22 13:08:36 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "25/05/22 13:08:36 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "25/05/22 13:08:37 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "25/05/22 13:08:37 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "25/05/22 13:08:37 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "25/05/22 13:08:38 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "25/05/22 13:08:39 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "25/05/22 13:08:39 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "25/05/22 13:08:40 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "25/05/22 13:08:40 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "25/05/22 13:08:40 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "25/05/22 13:08:41 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "25/05/22 13:08:41 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "25/05/22 13:08:42 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "25/05/22 13:08:43 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "25/05/22 13:08:43 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "25/05/22 13:08:43 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "25/05/22 13:08:44 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "25/05/22 13:08:44 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "25/05/22 13:08:44 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "25/05/22 13:08:45 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "25/05/22 13:08:47 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "25/05/22 13:09:08 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "25/05/22 13:09:29 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "25/05/22 13:09:49 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "25/05/22 13:10:09 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Accuracy: 0.926, Precision: 0.924, Recall: 0.926\n",
      "   F1: 0.925, AUC: 0.968\n"
     ]
    }
   ],
   "source": [
    "#Classification Models Training\n",
    "def train_classification_models(train_data, test_data):\n",
    "    print(\"\\nCLASSIFICATION MODELS TRAINING\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    accuracy_evaluator = MulticlassClassificationEvaluator(\n",
    "        labelCol=\"is_long_trip\", predictionCol=\"prediction\", metricName=\"accuracy\"\n",
    "    )\n",
    "    precision_evaluator = MulticlassClassificationEvaluator(\n",
    "        labelCol=\"is_long_trip\", predictionCol=\"prediction\", metricName=\"weightedPrecision\"\n",
    "    )\n",
    "    recall_evaluator = MulticlassClassificationEvaluator(\n",
    "        labelCol=\"is_long_trip\", predictionCol=\"prediction\", metricName=\"weightedRecall\"\n",
    "    )\n",
    "    f1_evaluator = MulticlassClassificationEvaluator(\n",
    "        labelCol=\"is_long_trip\", predictionCol=\"prediction\", metricName=\"f1\"\n",
    "    )\n",
    "    auc_evaluator = BinaryClassificationEvaluator(\n",
    "        labelCol=\"is_long_trip\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\"\n",
    "    )\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    print(\"\\n1. Logistic Regression\")\n",
    "    lr_clf = LogisticRegression(featuresCol=\"features\", labelCol=\"is_long_trip\")\n",
    "    lr_clf_model = lr_clf.fit(train_data)\n",
    "    lr_clf_predictions = lr_clf_model.transform(test_data)\n",
    "    \n",
    "    lr_accuracy = accuracy_evaluator.evaluate(lr_clf_predictions)\n",
    "    lr_precision = precision_evaluator.evaluate(lr_clf_predictions)\n",
    "    lr_recall = recall_evaluator.evaluate(lr_clf_predictions)\n",
    "    lr_f1 = f1_evaluator.evaluate(lr_clf_predictions)\n",
    "    lr_auc = auc_evaluator.evaluate(lr_clf_predictions)\n",
    "    \n",
    "    results['Logistic_Regression'] = {\n",
    "        'Accuracy': lr_accuracy, 'Precision': lr_precision, 'Recall': lr_recall,\n",
    "        'F1': lr_f1, 'AUC': lr_auc, 'model': lr_clf_model\n",
    "    }\n",
    "    \n",
    "    print(f\"   Accuracy: {lr_accuracy:.3f}, Precision: {lr_precision:.3f}, Recall: {lr_recall:.3f}\")\n",
    "    print(f\"   F1: {lr_f1:.3f}, AUC: {lr_auc:.3f}\")\n",
    "    \n",
    "    print(\"\\n2. Random Forest Classification\")\n",
    "    rf_clf = RandomForestClassifier(\n",
    "        featuresCol=\"features\", \n",
    "        labelCol=\"is_long_trip\",\n",
    "        numTrees=50, \n",
    "        maxDepth=10, \n",
    "        seed=42\n",
    "    )\n",
    "    rf_clf_model = rf_clf.fit(train_data)\n",
    "    rf_clf_predictions = rf_clf_model.transform(test_data)\n",
    "    \n",
    "    rf_accuracy = accuracy_evaluator.evaluate(rf_clf_predictions)\n",
    "    rf_precision = precision_evaluator.evaluate(rf_clf_predictions)\n",
    "    rf_recall = recall_evaluator.evaluate(rf_clf_predictions)\n",
    "    rf_f1 = f1_evaluator.evaluate(rf_clf_predictions)\n",
    "    rf_auc = auc_evaluator.evaluate(rf_clf_predictions)\n",
    "    \n",
    "    results['Random_Forest_Clf'] = {\n",
    "        'Accuracy': rf_accuracy, 'Precision': rf_precision, 'Recall': rf_recall,\n",
    "        'F1': rf_f1, 'AUC': rf_auc, 'model': rf_clf_model\n",
    "    }\n",
    "    \n",
    "    print(f\"   Accuracy: {rf_accuracy:.3f}, Precision: {rf_precision:.3f}, Recall: {rf_recall:.3f}\")\n",
    "    print(f\"   F1: {rf_f1:.3f}, AUC: {rf_auc:.3f}\")\n",
    "    \n",
    "    print(\"\\n3. Gradient Boosted Trees Classification\")\n",
    "    gbt_clf = GBTClassifier(\n",
    "        featuresCol=\"features\", \n",
    "        labelCol=\"is_long_trip\",\n",
    "        maxIter=50, \n",
    "        maxDepth=8, \n",
    "        seed=42\n",
    "    )\n",
    "    gbt_clf_model = gbt_clf.fit(train_data)\n",
    "    gbt_clf_predictions = gbt_clf_model.transform(test_data)\n",
    "    \n",
    "    gbt_accuracy = accuracy_evaluator.evaluate(gbt_clf_predictions)\n",
    "    gbt_precision = precision_evaluator.evaluate(gbt_clf_predictions)\n",
    "    gbt_recall = recall_evaluator.evaluate(gbt_clf_predictions)\n",
    "    gbt_f1 = f1_evaluator.evaluate(gbt_clf_predictions)\n",
    "    gbt_auc = auc_evaluator.evaluate(gbt_clf_predictions)\n",
    "    \n",
    "    results['Gradient_Boosted_Trees_Clf'] = {\n",
    "        'Accuracy': gbt_accuracy, 'Precision': gbt_precision, 'Recall': gbt_recall,\n",
    "        'F1': gbt_f1, 'AUC': gbt_auc, 'model': gbt_clf_model\n",
    "    }\n",
    "    \n",
    "    print(f\"   Accuracy: {gbt_accuracy:.3f}, Precision: {gbt_precision:.3f}, Recall: {gbt_recall:.3f}\")\n",
    "    print(f\"   F1: {gbt_f1:.3f}, AUC: {gbt_auc:.3f}\")\n",
    "    \n",
    "    return results, rf_clf_predictions\n",
    "\n",
    "classification_results, clf_predictions = train_classification_models(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c151d72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "QUICK MODEL TESTING\n",
      "========================================\n",
      "Rush hour Manhattan: 18.0 minutes (2.5 miles)\n",
      "Evening long trip: 33.6 minutes (12.8 miles)\n",
      "Short night trip: 5.7 minutes (1.1 miles)\n",
      "\n",
      "FINAL RESULTS\n",
      "========================================\n",
      "BEST REGRESSION MODEL:\n",
      "  Gradient_Boosted_Trees\n",
      "  RMSE: 4.22 minutes\n",
      "  R²: 0.837 (83.7% accuracy)\n",
      "\n",
      "BEST CLASSIFICATION MODEL:\n",
      "  Gradient_Boosted_Trees_Clf\n",
      "  Accuracy: 0.926 (92.6%)\n",
      "  F1-Score: 0.925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1838:========================================>             (15 + 5) / 20]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DATASET: 11,937,106 taxi trips processed\n",
      "ALGORITHMS: Linear Regression, Random Forest, Gradient Boosted Trees\n",
      "EVALUATION: Train-Test Split (70/30), RMSE, MAE, R², Accuracy, F1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def test_models_quick():\n",
    "    print(\"\\nQUICK MODEL TESTING\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    best_reg_model = regression_results['Random_Forest']['model']\n",
    "    \n",
    "    # Test scenarios\n",
    "    test_cases = [\n",
    "        (\"Rush hour Manhattan\", 8, 2, 1, 2.5, -73.9851, 40.7589, -73.9934, 40.7505),\n",
    "        (\"Evening long trip\", 22, 6, 3, 12.8, -73.7949, 40.7282, -74.0445, 40.6892),\n",
    "        (\"Short night trip\", 2, 3, 1, 1.1, -73.9851, 40.7589, -73.9934, 40.7505)\n",
    "    ]\n",
    "    \n",
    "    for desc, hour, day, passengers, distance, p_lon, p_lat, d_lon, d_lat in test_cases:\n",
    "        # Create test data\n",
    "        test_data = spark.createDataFrame([\n",
    "            (hour, day, passengers, distance, p_lon, p_lat, d_lon, d_lat)\n",
    "        ], StructType([\n",
    "            StructField(\"pickup_hour\", IntegerType(), True),\n",
    "            StructField(\"pickup_day_of_week\", IntegerType(), True),\n",
    "            StructField(\"passenger_count\", IntegerType(), True),\n",
    "            StructField(\"trip_distance\", DoubleType(), True),\n",
    "            StructField(\"pickup_longitude\", DoubleType(), True),\n",
    "            StructField(\"pickup_latitude\", DoubleType(), True),\n",
    "            StructField(\"dropoff_longitude\", DoubleType(), True),\n",
    "            StructField(\"dropoff_latitude\", DoubleType(), True)\n",
    "        ]))\n",
    "        \n",
    "        # Add features\n",
    "        test_data = test_data.withColumn(\"pickup_month\", lit(3)) \\\n",
    "                           .withColumn(\"pickup_day_of_year\", lit(60)) \\\n",
    "                           .withColumn(\"is_weekend\", when(col(\"pickup_day_of_week\").isin([1, 7]), 1).otherwise(0)) \\\n",
    "                           .withColumn(\"hour_category\", when(col(\"pickup_hour\").between(6, 12), \"Morning\")\n",
    "                                                      .when(col(\"pickup_hour\").between(13, 18), \"Afternoon\")\n",
    "                                                      .when(col(\"pickup_hour\").between(19, 22), \"Evening\")\n",
    "                                                      .otherwise(\"Night\")) \\\n",
    "                           .withColumn(\"calculated_distance\", calculate_haversine_distance(\n",
    "                               col(\"pickup_latitude\"), col(\"pickup_longitude\"),\n",
    "                               col(\"dropoff_latitude\"), col(\"dropoff_longitude\"))) \\\n",
    "                           .withColumn(\"trip_duration_minutes\", lit(0.0)) \\\n",
    "                           .withColumn(\"trip_category\", lit(\"Unknown\")) \\\n",
    "                           .withColumn(\"is_long_trip\", lit(0.0))\n",
    "        \n",
    "        # Predict\n",
    "        test_processed = preprocessing_model.transform(test_data)\n",
    "        prediction = best_reg_model.transform(test_processed)\n",
    "        duration = prediction.select(\"prediction\").collect()[0][\"prediction\"]\n",
    "        \n",
    "        print(f\"{desc}: {duration:.1f} minutes ({distance:.1f} miles)\")\n",
    "\n",
    "test_models_quick()\n",
    "\n",
    "# Results Summary\n",
    "def final_summary():\n",
    "    print(\"\\nFINAL RESULTS\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Fix: Use Python's built-in min/max explicitly\n",
    "    import builtins\n",
    "    \n",
    "    best_reg = builtins.min(regression_results.items(), key=lambda x: x[1]['RMSE'])\n",
    "    best_clf = builtins.max(classification_results.items(), key=lambda x: x[1]['F1'])\n",
    "    \n",
    "    print(\"BEST REGRESSION MODEL:\")\n",
    "    print(f\"  {best_reg[0]}\")\n",
    "    print(f\"  RMSE: {best_reg[1]['RMSE']:.2f} minutes\")\n",
    "    print(f\"  R²: {best_reg[1]['R²']:.3f} ({best_reg[1]['R²']*100:.1f}% accuracy)\")\n",
    "    \n",
    "    print(\"\\nBEST CLASSIFICATION MODEL:\")\n",
    "    print(f\"  {best_clf[0]}\")\n",
    "    print(f\"  Accuracy: {best_clf[1]['Accuracy']:.3f} ({best_clf[1]['Accuracy']*100:.1f}%)\")\n",
    "    print(f\"  F1-Score: {best_clf[1]['F1']:.3f}\")\n",
    "    \n",
    "    print(f\"\\nDATASET: {df_processed.count():,} taxi trips processed\")\n",
    "    print(\"ALGORITHMS: Linear Regression, Random Forest, Gradient Boosted Trees\")\n",
    "    print(\"EVALUATION: Train-Test Split (70/30), RMSE, MAE, R², Accuracy, F1\")\n",
    "\n",
    "final_summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
